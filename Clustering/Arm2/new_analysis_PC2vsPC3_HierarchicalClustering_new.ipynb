{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ttest_ind, wilcoxon\n",
    "from chord import Chord\n",
    "import operator\n",
    "#sklearn imports\n",
    "from sklearn.decomposition import PCA #Principal Component Analysis\n",
    "from sklearn.manifold import TSNE #T-Distributed Stochastic Neighbor Embedding\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler #used for 'Feature Scaling'\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#############################\n",
    "# Princple Feature Analysis #\n",
    "# PFA is based on http://venom.cs.utsa.edu/dmz/techrep/2007/CS-TR-2007-011.pdf #\n",
    "#############################\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internalValidation(data, clusters):\n",
    "    scores = {}\n",
    "    \"\"\"\n",
    "    The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. \n",
    "    Scores around zero indicate overlapping clusters.\n",
    "    The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.\n",
    "    \"\"\"\n",
    "    scores['_silhouette_score'] =metrics.silhouette_score(data,clusters ,metric='euclidean')\n",
    "    \"\"\"\n",
    "    The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.\n",
    "    The score is fast to compute\n",
    "    \"\"\"\n",
    "    scores['_calinski_harabaz_score'] = metrics.calinski_harabaz_score(data,clusters)\n",
    "    \"\"\"\n",
    "    Zero is the lowest possible score. Values closer to zero indicate a better partition.\n",
    "    The Davies-Boulding index is generally higher for convex clusters than other concepts of clusters, \n",
    "    such as density based clusters like those obtained from DBSCAN.\n",
    "    \"\"\"\n",
    "    scores['_davies_bouldin_score'] = metrics.davies_bouldin_score(data,clusters)\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data importing and some cleaning\n",
    "'''\n",
    "mdd_master = pd.read_excel('MDD Master Sheet Sapient.xlsx', \n",
    "                           header = [0,1], \n",
    "                           sheet_name = 'MasterImagingOnly',\n",
    "                           skiprows=[85,86,87,88,89,90,91,92,93,94,95])\n",
    "mdd_master.columns = ['{} {}'.format(i, j) for i, j in mdd_master.columns]\n",
    "'''\n",
    "#mdd_master =pd.read_csv('/Users/xinxing/Documents/MDD/New data/MDD_test/MDD_data_demo.csv')\n",
    "df=pd.read_excel('/Users/xinxing/Documents/MDD/New data/MDD_test/May_03_2021/MDD_data_Gaurav.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist=['7T ID','Label','madrs_sum','qids_score','mddonset','mddc_duration', 'madrs_sum',\n",
    "         'pss_score','btq_score','lsc_score','ce_tleq','oc_tleq','qids_score','rrs_total',\n",
    "         'shaps_score_1','shaps_score_2','bss_total','sticsa_somatic','sticsa_cognitive'\n",
    "          ]\n",
    "df=df[df.Status==0]\n",
    "mdd_master=df.drop(droplist,axis=1)\n",
    "mdd_master=mdd_master[mdd_master.Status==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XNAT</th>\n",
       "      <th>Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Education</th>\n",
       "      <th>...</th>\n",
       "      <th>N_Right-VentralDC</th>\n",
       "      <th>N_Right-vessel</th>\n",
       "      <th>N_Right-choroid-plexus</th>\n",
       "      <th>N_WM-hypointensities</th>\n",
       "      <th>N_Optic-Chiasm</th>\n",
       "      <th>N_CC_Posterior</th>\n",
       "      <th>N_CC_Mid_Posterior</th>\n",
       "      <th>N_CC_Central</th>\n",
       "      <th>N_CC_Mid_Anterior</th>\n",
       "      <th>N_CC_Anterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S02794</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>1.524000</td>\n",
       "      <td>88.450523</td>\n",
       "      <td>38.082940</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.804401</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.532276</td>\n",
       "      <td>1.894469</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>1.071083</td>\n",
       "      <td>0.342685</td>\n",
       "      <td>0.428260</td>\n",
       "      <td>0.397046</td>\n",
       "      <td>0.982338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S02855</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>1.625603</td>\n",
       "      <td>74.842751</td>\n",
       "      <td>28.321785</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.505706</td>\n",
       "      <td>0.054691</td>\n",
       "      <td>0.707489</td>\n",
       "      <td>2.695649</td>\n",
       "      <td>0.132873</td>\n",
       "      <td>0.918633</td>\n",
       "      <td>0.341327</td>\n",
       "      <td>0.434571</td>\n",
       "      <td>0.477965</td>\n",
       "      <td>1.151384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S03843</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>1.752604</td>\n",
       "      <td>87.543339</td>\n",
       "      <td>28.500715</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.607140</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.370024</td>\n",
       "      <td>2.645058</td>\n",
       "      <td>0.190682</td>\n",
       "      <td>1.041461</td>\n",
       "      <td>0.633224</td>\n",
       "      <td>0.542124</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>1.224615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S04179</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>1.905004</td>\n",
       "      <td>117.934031</td>\n",
       "      <td>32.497312</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.724191</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.840838</td>\n",
       "      <td>4.193174</td>\n",
       "      <td>0.091664</td>\n",
       "      <td>0.845333</td>\n",
       "      <td>0.539141</td>\n",
       "      <td>0.481499</td>\n",
       "      <td>0.507147</td>\n",
       "      <td>1.005833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S03872</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>M</td>\n",
       "      <td>1.778004</td>\n",
       "      <td>68.038864</td>\n",
       "      <td>21.522455</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.597112</td>\n",
       "      <td>0.061952</td>\n",
       "      <td>0.627542</td>\n",
       "      <td>1.993024</td>\n",
       "      <td>0.120772</td>\n",
       "      <td>0.928297</td>\n",
       "      <td>0.395101</td>\n",
       "      <td>0.402050</td>\n",
       "      <td>0.427790</td>\n",
       "      <td>1.045936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S05510</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>1.828804</td>\n",
       "      <td>99.790334</td>\n",
       "      <td>29.836942</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.957966</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.540291</td>\n",
       "      <td>1.353151</td>\n",
       "      <td>0.188105</td>\n",
       "      <td>1.192518</td>\n",
       "      <td>0.491164</td>\n",
       "      <td>0.528332</td>\n",
       "      <td>0.494288</td>\n",
       "      <td>0.942896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S05486</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>1.701803</td>\n",
       "      <td>68.038864</td>\n",
       "      <td>23.492989</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.898135</td>\n",
       "      <td>0.088655</td>\n",
       "      <td>0.411647</td>\n",
       "      <td>0.836225</td>\n",
       "      <td>0.079911</td>\n",
       "      <td>0.987209</td>\n",
       "      <td>0.739755</td>\n",
       "      <td>0.506814</td>\n",
       "      <td>0.679660</td>\n",
       "      <td>0.825341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S06444</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>1.752604</td>\n",
       "      <td>74.842751</td>\n",
       "      <td>24.365896</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.432859</td>\n",
       "      <td>0.057682</td>\n",
       "      <td>0.693337</td>\n",
       "      <td>5.674513</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>1.199062</td>\n",
       "      <td>0.374743</td>\n",
       "      <td>0.449960</td>\n",
       "      <td>0.659992</td>\n",
       "      <td>0.993821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S06720</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>1.676400</td>\n",
       "      <td>104.326258</td>\n",
       "      <td>37.122595</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.758795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870250</td>\n",
       "      <td>2.967984</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>1.122694</td>\n",
       "      <td>0.614419</td>\n",
       "      <td>0.618096</td>\n",
       "      <td>0.708469</td>\n",
       "      <td>1.206681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S07052</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>1.600203</td>\n",
       "      <td>49.895167</td>\n",
       "      <td>19.485350</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811041</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>2.294796</td>\n",
       "      <td>0.146332</td>\n",
       "      <td>0.961843</td>\n",
       "      <td>0.482619</td>\n",
       "      <td>0.777922</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>0.938209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S07470</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727203</td>\n",
       "      <td>58.967016</td>\n",
       "      <td>19.766153</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.605918</td>\n",
       "      <td>0.108884</td>\n",
       "      <td>0.591281</td>\n",
       "      <td>2.653043</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.847240</td>\n",
       "      <td>0.615748</td>\n",
       "      <td>0.583787</td>\n",
       "      <td>0.494404</td>\n",
       "      <td>1.128661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S07735</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "      <td>1.955804</td>\n",
       "      <td>115.666069</td>\n",
       "      <td>30.238160</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.590627</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.441208</td>\n",
       "      <td>8.359756</td>\n",
       "      <td>0.173129</td>\n",
       "      <td>0.794929</td>\n",
       "      <td>0.361183</td>\n",
       "      <td>0.469435</td>\n",
       "      <td>0.509780</td>\n",
       "      <td>0.816357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S07760</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>1.625603</td>\n",
       "      <td>74.842751</td>\n",
       "      <td>28.321785</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.169538</td>\n",
       "      <td>0.046690</td>\n",
       "      <td>0.477808</td>\n",
       "      <td>2.381470</td>\n",
       "      <td>0.089841</td>\n",
       "      <td>1.062658</td>\n",
       "      <td>0.730325</td>\n",
       "      <td>0.738778</td>\n",
       "      <td>0.706341</td>\n",
       "      <td>1.073273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S08098</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>1.778004</td>\n",
       "      <td>95.254410</td>\n",
       "      <td>30.131437</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.966572</td>\n",
       "      <td>0.058773</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>3.587062</td>\n",
       "      <td>0.162882</td>\n",
       "      <td>0.858924</td>\n",
       "      <td>0.483162</td>\n",
       "      <td>0.520181</td>\n",
       "      <td>0.590470</td>\n",
       "      <td>0.923638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S08643</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>1.778004</td>\n",
       "      <td>102.058296</td>\n",
       "      <td>32.283682</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.649148</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.454444</td>\n",
       "      <td>4.225318</td>\n",
       "      <td>0.087743</td>\n",
       "      <td>0.961657</td>\n",
       "      <td>0.710494</td>\n",
       "      <td>0.694992</td>\n",
       "      <td>0.707516</td>\n",
       "      <td>0.981053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S09132</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>1.879604</td>\n",
       "      <td>72.574788</td>\n",
       "      <td>20.542494</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.504909</td>\n",
       "      <td>0.026724</td>\n",
       "      <td>0.519555</td>\n",
       "      <td>4.496510</td>\n",
       "      <td>0.137449</td>\n",
       "      <td>0.664506</td>\n",
       "      <td>0.288494</td>\n",
       "      <td>0.382419</td>\n",
       "      <td>0.328424</td>\n",
       "      <td>0.842900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S09400</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.701803</td>\n",
       "      <td>58.967016</td>\n",
       "      <td>20.360591</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811494</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.572358</td>\n",
       "      <td>2.036600</td>\n",
       "      <td>0.089218</td>\n",
       "      <td>0.797693</td>\n",
       "      <td>0.637394</td>\n",
       "      <td>0.559487</td>\n",
       "      <td>0.534136</td>\n",
       "      <td>0.906705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S09530</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>1.828804</td>\n",
       "      <td>65.770902</td>\n",
       "      <td>19.665257</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.957653</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.391789</td>\n",
       "      <td>3.299343</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.836174</td>\n",
       "      <td>0.487374</td>\n",
       "      <td>0.565008</td>\n",
       "      <td>0.534065</td>\n",
       "      <td>0.695473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S09706</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>1.752604</td>\n",
       "      <td>127.005880</td>\n",
       "      <td>41.348187</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.908508</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.680834</td>\n",
       "      <td>4.487187</td>\n",
       "      <td>0.178177</td>\n",
       "      <td>1.084404</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.545122</td>\n",
       "      <td>0.605603</td>\n",
       "      <td>1.047977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S09727</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>1.778004</td>\n",
       "      <td>86.182561</td>\n",
       "      <td>27.261776</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.586329</td>\n",
       "      <td>0.020861</td>\n",
       "      <td>0.516099</td>\n",
       "      <td>2.241400</td>\n",
       "      <td>0.102350</td>\n",
       "      <td>1.117061</td>\n",
       "      <td>0.416679</td>\n",
       "      <td>0.497369</td>\n",
       "      <td>0.734735</td>\n",
       "      <td>0.923989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S10046</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>1.625603</td>\n",
       "      <td>61.688570</td>\n",
       "      <td>23.344017</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.559510</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.664180</td>\n",
       "      <td>2.072942</td>\n",
       "      <td>0.122719</td>\n",
       "      <td>1.057918</td>\n",
       "      <td>0.562716</td>\n",
       "      <td>0.613400</td>\n",
       "      <td>0.648119</td>\n",
       "      <td>0.956166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>S10437</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>1.854204</td>\n",
       "      <td>77.110713</td>\n",
       "      <td>22.428479</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.630624</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>3.036317</td>\n",
       "      <td>0.114849</td>\n",
       "      <td>0.770486</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>0.420758</td>\n",
       "      <td>0.580742</td>\n",
       "      <td>0.861083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>S10643</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1.651003</td>\n",
       "      <td>61.688570</td>\n",
       "      <td>22.631264</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105072</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.388754</td>\n",
       "      <td>0.929132</td>\n",
       "      <td>0.097189</td>\n",
       "      <td>0.985964</td>\n",
       "      <td>0.562589</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.832777</td>\n",
       "      <td>1.068449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>S10638</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>1.752604</td>\n",
       "      <td>67.131679</td>\n",
       "      <td>21.855470</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162398</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.398774</td>\n",
       "      <td>2.048358</td>\n",
       "      <td>0.071164</td>\n",
       "      <td>1.116735</td>\n",
       "      <td>0.587760</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.643933</td>\n",
       "      <td>1.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>S10686</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>1.651003</td>\n",
       "      <td>55.338276</td>\n",
       "      <td>20.301575</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.596912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513085</td>\n",
       "      <td>1.773324</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>1.082053</td>\n",
       "      <td>0.702005</td>\n",
       "      <td>0.638196</td>\n",
       "      <td>0.774142</td>\n",
       "      <td>1.008612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>S10725</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>1.625603</td>\n",
       "      <td>56.699053</td>\n",
       "      <td>21.455898</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.616011</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.467825</td>\n",
       "      <td>2.933539</td>\n",
       "      <td>0.101669</td>\n",
       "      <td>0.884135</td>\n",
       "      <td>0.489918</td>\n",
       "      <td>0.444371</td>\n",
       "      <td>0.443952</td>\n",
       "      <td>0.917012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>S11544</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>1.625603</td>\n",
       "      <td>75.749935</td>\n",
       "      <td>28.665079</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.187495</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.514675</td>\n",
       "      <td>2.260984</td>\n",
       "      <td>0.081035</td>\n",
       "      <td>0.957026</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.782294</td>\n",
       "      <td>0.796070</td>\n",
       "      <td>0.822913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>S11597</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>1.625603</td>\n",
       "      <td>58.967016</td>\n",
       "      <td>22.314134</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.576572</td>\n",
       "      <td>0.113848</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>3.382715</td>\n",
       "      <td>0.063906</td>\n",
       "      <td>0.960316</td>\n",
       "      <td>0.639667</td>\n",
       "      <td>0.540802</td>\n",
       "      <td>0.466501</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>S11844</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>1.879604</td>\n",
       "      <td>63.502940</td>\n",
       "      <td>17.974682</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.711145</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>0.550193</td>\n",
       "      <td>1.504507</td>\n",
       "      <td>0.145647</td>\n",
       "      <td>0.827287</td>\n",
       "      <td>0.628500</td>\n",
       "      <td>0.497393</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>0.671268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>S12050</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.600203</td>\n",
       "      <td>79.378675</td>\n",
       "      <td>30.999420</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.560604</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.653454</td>\n",
       "      <td>2.129043</td>\n",
       "      <td>0.074309</td>\n",
       "      <td>0.822971</td>\n",
       "      <td>0.512731</td>\n",
       "      <td>0.459786</td>\n",
       "      <td>0.614442</td>\n",
       "      <td>0.899231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>S12142</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>1.828804</td>\n",
       "      <td>74.842751</td>\n",
       "      <td>22.377707</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.441816</td>\n",
       "      <td>0.044024</td>\n",
       "      <td>0.322060</td>\n",
       "      <td>4.746918</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.777285</td>\n",
       "      <td>0.525944</td>\n",
       "      <td>0.619767</td>\n",
       "      <td>0.587452</td>\n",
       "      <td>0.774397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>S12185</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>1.778004</td>\n",
       "      <td>81.646637</td>\n",
       "      <td>25.826946</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211715</td>\n",
       "      <td>0.040151</td>\n",
       "      <td>0.396425</td>\n",
       "      <td>6.708483</td>\n",
       "      <td>0.098544</td>\n",
       "      <td>1.258663</td>\n",
       "      <td>0.493969</td>\n",
       "      <td>0.523541</td>\n",
       "      <td>0.555111</td>\n",
       "      <td>1.215930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>S12452</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>1.828804</td>\n",
       "      <td>90.718486</td>\n",
       "      <td>27.124493</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.837258</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>0.406188</td>\n",
       "      <td>4.557100</td>\n",
       "      <td>0.137783</td>\n",
       "      <td>1.234840</td>\n",
       "      <td>0.512068</td>\n",
       "      <td>0.506209</td>\n",
       "      <td>0.587186</td>\n",
       "      <td>1.124402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>S12858</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>O</td>\n",
       "      <td>1.727203</td>\n",
       "      <td>79.378675</td>\n",
       "      <td>26.608283</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.755489</td>\n",
       "      <td>0.024316</td>\n",
       "      <td>0.466596</td>\n",
       "      <td>3.017353</td>\n",
       "      <td>0.213713</td>\n",
       "      <td>0.994820</td>\n",
       "      <td>0.598696</td>\n",
       "      <td>0.705596</td>\n",
       "      <td>0.616469</td>\n",
       "      <td>0.831331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>S12879</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>1.828804</td>\n",
       "      <td>117.026846</td>\n",
       "      <td>34.990596</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.860695</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.434204</td>\n",
       "      <td>2.612509</td>\n",
       "      <td>0.251729</td>\n",
       "      <td>1.067082</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.457517</td>\n",
       "      <td>0.516314</td>\n",
       "      <td>0.825296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>S13146</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>1.854204</td>\n",
       "      <td>81.646637</td>\n",
       "      <td>23.747801</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305261</td>\n",
       "      <td>0.037768</td>\n",
       "      <td>0.490034</td>\n",
       "      <td>1.924255</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>0.838911</td>\n",
       "      <td>0.520366</td>\n",
       "      <td>0.460764</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>0.841625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>S14429</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>1.676403</td>\n",
       "      <td>72.574788</td>\n",
       "      <td>25.824311</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.367612</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.375511</td>\n",
       "      <td>2.657202</td>\n",
       "      <td>0.057649</td>\n",
       "      <td>0.858693</td>\n",
       "      <td>0.478229</td>\n",
       "      <td>0.626215</td>\n",
       "      <td>0.684260</td>\n",
       "      <td>0.983302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>S15152</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>1.549403</td>\n",
       "      <td>45.359243</td>\n",
       "      <td>18.894567</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.654947</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.417136</td>\n",
       "      <td>2.295790</td>\n",
       "      <td>0.174801</td>\n",
       "      <td>0.914121</td>\n",
       "      <td>0.536043</td>\n",
       "      <td>0.545856</td>\n",
       "      <td>0.636383</td>\n",
       "      <td>0.917200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>S15183</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>1.854204</td>\n",
       "      <td>89.811301</td>\n",
       "      <td>26.122582</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.656367</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.406544</td>\n",
       "      <td>3.050013</td>\n",
       "      <td>0.113843</td>\n",
       "      <td>0.849195</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>0.691105</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.699805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>S15604</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>1.752604</td>\n",
       "      <td>90.718486</td>\n",
       "      <td>29.534419</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.055184</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.645477</td>\n",
       "      <td>7.718679</td>\n",
       "      <td>0.148265</td>\n",
       "      <td>1.009132</td>\n",
       "      <td>0.463156</td>\n",
       "      <td>0.416959</td>\n",
       "      <td>0.465821</td>\n",
       "      <td>0.809734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>S00554</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>1.549399</td>\n",
       "      <td>56.699114</td>\n",
       "      <td>23.618354</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.641629</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.446421</td>\n",
       "      <td>1.829644</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.696501</td>\n",
       "      <td>0.327363</td>\n",
       "      <td>0.583804</td>\n",
       "      <td>0.541174</td>\n",
       "      <td>0.754891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>S00880</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>1.676399</td>\n",
       "      <td>55.791928</td>\n",
       "      <td>19.852561</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.847024</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.381319</td>\n",
       "      <td>0.675023</td>\n",
       "      <td>0.075510</td>\n",
       "      <td>0.939058</td>\n",
       "      <td>0.557740</td>\n",
       "      <td>0.716796</td>\n",
       "      <td>0.844498</td>\n",
       "      <td>0.932907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      XNAT  Status  Age Gender    Height      Weight        BMI  Race  \\\n",
       "0   S02794       0   40      M  1.524000   88.450523  38.082940     5   \n",
       "1   S02855       0   49      F  1.625603   74.842751  28.321785     5   \n",
       "2   S03843       0   45      M  1.752604   87.543339  28.500715     3   \n",
       "3   S04179       0   51      M  1.905004  117.934031  32.497312     5   \n",
       "4   S03872       0   55      M  1.778004   68.038864  21.522455     5   \n",
       "5   S05510       0   53      M  1.828804   99.790334  29.836942     5   \n",
       "6   S05486       0   39      F  1.701803   68.038864  23.492989     5   \n",
       "7   S06444       0   54      M  1.752604   74.842751  24.365896     5   \n",
       "8   S06720       0   29      F  1.676400  104.326258  37.122595     6   \n",
       "11  S07052       0   41      F  1.600203   49.895167  19.485350     5   \n",
       "13  S07470       0   32      M  1.727203   58.967016  19.766153     5   \n",
       "16  S07735       0   50      M  1.955804  115.666069  30.238160     5   \n",
       "19  S07760       0   46      F  1.625603   74.842751  28.321785     6   \n",
       "22  S08098       0   54      M  1.778004   95.254410  30.131437     3   \n",
       "25  S08643       0   24      M  1.778004  102.058296  32.283682     5   \n",
       "28  S09132       0   26      M  1.879604   72.574788  20.542494     5   \n",
       "30  S09400       0   25      F  1.701803   58.967016  20.360591     5   \n",
       "31  S09530       0   38      M  1.828804   65.770902  19.665257     5   \n",
       "32  S09706       0   27      F  1.752604  127.005880  41.348187     3   \n",
       "33  S09727       0   47      M  1.778004   86.182561  27.261776     5   \n",
       "36  S10046       0   24      F  1.625603   61.688570  23.344017     3   \n",
       "38  S10437       0   29      M  1.854204   77.110713  22.428479     5   \n",
       "40  S10643       0   33      F  1.651003   61.688570  22.631264     3   \n",
       "41  S10638       0   37      F  1.752604   67.131679  21.855470     5   \n",
       "45  S10686       0   30      F  1.651003   55.338276  20.301575     5   \n",
       "46  S10725       0   63      M  1.625603   56.699053  21.455898     5   \n",
       "54  S11544       0   34      F  1.625603   75.749935  28.665079     3   \n",
       "55  S11597       0   30      F  1.625603   58.967016  22.314134     7   \n",
       "57  S11844       0   24      M  1.879604   63.502940  17.974682     5   \n",
       "58  S12050       0   26      F  1.600203   79.378675  30.999420     5   \n",
       "59  S12142       0   27      M  1.828804   74.842751  22.377707     5   \n",
       "60  S12185       0   43      M  1.778004   81.646637  25.826946     5   \n",
       "61  S12452       0   46      M  1.828804   90.718486  27.124493     7   \n",
       "62  S12858       0   51      O  1.727203   79.378675  26.608283     2   \n",
       "63  S12879       0   38      M  1.828804  117.026846  34.990596     5   \n",
       "64  S13146       0   63      M  1.854204   81.646637  23.747801     3   \n",
       "68  S14429       0   43      F  1.676403   72.574788  25.824311     5   \n",
       "73  S15152       0   27      F  1.549403   45.359243  18.894567     2   \n",
       "74  S15183       0   32      M  1.854204   89.811301  26.122582     5   \n",
       "79  S15604       0   30      M  1.752604   90.718486  29.534419     5   \n",
       "84  S00554       0   20      F  1.549399   56.699114  23.618354     5   \n",
       "87  S00880       0   30      M  1.676399   55.791928  19.852561     2   \n",
       "\n",
       "    Ethnicity  Education  ...  N_Right-VentralDC  N_Right-vessel  \\\n",
       "0         3.0        6.0  ...           3.804401        0.025932   \n",
       "1         2.0        NaN  ...           3.505706        0.054691   \n",
       "2         NaN        4.0  ...           3.607140        0.012102   \n",
       "3         2.0        5.0  ...           3.724191        0.017628   \n",
       "4         2.0        6.0  ...           3.597112        0.061952   \n",
       "5         1.0        2.0  ...           3.957966        0.013144   \n",
       "6         2.0        8.0  ...           3.898135        0.088655   \n",
       "7         2.0        5.0  ...           3.432859        0.057682   \n",
       "8         1.0        6.0  ...           3.758795        0.000000   \n",
       "11        2.0        8.0  ...           3.811041        0.002389   \n",
       "13        2.0        7.0  ...           3.605918        0.108884   \n",
       "16        2.0        6.0  ...           3.590627        0.004064   \n",
       "19        2.0        8.0  ...           4.169538        0.046690   \n",
       "22        2.0        2.0  ...           3.966572        0.058773   \n",
       "25        2.0        7.0  ...           3.649148        0.014586   \n",
       "28        2.0        7.0  ...           3.504909        0.026724   \n",
       "30        1.0        6.0  ...           3.811494        0.022329   \n",
       "31        2.0        6.0  ...           3.957653        0.005826   \n",
       "32        1.0        4.0  ...           3.908508        0.006335   \n",
       "33        2.0        6.0  ...           3.586329        0.020861   \n",
       "36        2.0        7.0  ...           3.559510        0.037219   \n",
       "38        2.0        7.0  ...           3.630624        0.022690   \n",
       "40        2.0        4.0  ...           4.105072        0.031284   \n",
       "41        2.0        6.0  ...           3.162398        0.015749   \n",
       "45        2.0        6.0  ...           3.596912        0.000000   \n",
       "46        2.0        8.0  ...           3.616011        0.008481   \n",
       "54        2.0        6.0  ...           4.187495        0.060067   \n",
       "55        2.0        8.0  ...           3.576572        0.113848   \n",
       "57        2.0        7.0  ...           3.711145        0.028568   \n",
       "58        2.0        7.0  ...           3.560604        0.009846   \n",
       "59        2.0        4.0  ...           3.441816        0.044024   \n",
       "60        1.0        4.0  ...           3.211715        0.040151   \n",
       "61        3.0        7.0  ...           3.837258        0.044680   \n",
       "62        2.0        3.0  ...           3.755489        0.024316   \n",
       "63        2.0        6.0  ...           3.860695        0.110651   \n",
       "64        2.0        5.0  ...           4.305261        0.037768   \n",
       "68        2.0        5.0  ...           3.367612        0.010004   \n",
       "73        2.0        6.0  ...           3.654947        0.026841   \n",
       "74        2.0        6.0  ...           3.656367        0.027689   \n",
       "79        2.0        8.0  ...           4.055184        0.001382   \n",
       "84        1.0        3.0  ...           3.641629        0.022027   \n",
       "87        2.0        6.0  ...           3.847024        0.008732   \n",
       "\n",
       "    N_Right-choroid-plexus  N_WM-hypointensities  N_Optic-Chiasm  \\\n",
       "0                 0.532276              1.894469        0.092779   \n",
       "1                 0.707489              2.695649        0.132873   \n",
       "2                 0.370024              2.645058        0.190682   \n",
       "3                 0.840838              4.193174        0.091664   \n",
       "4                 0.627542              1.993024        0.120772   \n",
       "5                 0.540291              1.353151        0.188105   \n",
       "6                 0.411647              0.836225        0.079911   \n",
       "7                 0.693337              5.674513        0.052029   \n",
       "8                 0.870250              2.967984        0.129657   \n",
       "11                0.537179              2.294796        0.146332   \n",
       "13                0.591281              2.653043        0.102113   \n",
       "16                0.441208              8.359756        0.173129   \n",
       "19                0.477808              2.381470        0.089841   \n",
       "22                0.363971              3.587062        0.162882   \n",
       "25                0.454444              4.225318        0.087743   \n",
       "28                0.519555              4.496510        0.137449   \n",
       "30                0.572358              2.036600        0.089218   \n",
       "31                0.391789              3.299343        0.027872   \n",
       "32                0.680834              4.487187        0.178177   \n",
       "33                0.516099              2.241400        0.102350   \n",
       "36                0.664180              2.072942        0.122719   \n",
       "38                0.469592              3.036317        0.114849   \n",
       "40                0.388754              0.929132        0.097189   \n",
       "41                0.398774              2.048358        0.071164   \n",
       "45                0.513085              1.773324        0.065014   \n",
       "46                0.467825              2.933539        0.101669   \n",
       "54                0.514675              2.260984        0.081035   \n",
       "55                0.559046              3.382715        0.063906   \n",
       "57                0.550193              1.504507        0.145647   \n",
       "58                0.653454              2.129043        0.074309   \n",
       "59                0.322060              4.746918        0.130900   \n",
       "60                0.396425              6.708483        0.098544   \n",
       "61                0.406188              4.557100        0.137783   \n",
       "62                0.466596              3.017353        0.213713   \n",
       "63                0.434204              2.612509        0.251729   \n",
       "64                0.490034              1.924255        0.195683   \n",
       "68                0.375511              2.657202        0.057649   \n",
       "73                0.417136              2.295790        0.174801   \n",
       "74                0.406544              3.050013        0.113843   \n",
       "79                0.645477              7.718679        0.148265   \n",
       "84                0.446421              1.829644        0.069783   \n",
       "87                0.381319              0.675023        0.075510   \n",
       "\n",
       "    N_CC_Posterior  N_CC_Mid_Posterior  N_CC_Central  N_CC_Mid_Anterior  \\\n",
       "0         1.071083            0.342685      0.428260           0.397046   \n",
       "1         0.918633            0.341327      0.434571           0.477965   \n",
       "2         1.041461            0.633224      0.542124           0.558800   \n",
       "3         0.845333            0.539141      0.481499           0.507147   \n",
       "4         0.928297            0.395101      0.402050           0.427790   \n",
       "5         1.192518            0.491164      0.528332           0.494288   \n",
       "6         0.987209            0.739755      0.506814           0.679660   \n",
       "7         1.199062            0.374743      0.449960           0.659992   \n",
       "8         1.122694            0.614419      0.618096           0.708469   \n",
       "11        0.961843            0.482619      0.777922           0.734048   \n",
       "13        0.847240            0.615748      0.583787           0.494404   \n",
       "16        0.794929            0.361183      0.469435           0.509780   \n",
       "19        1.062658            0.730325      0.738778           0.706341   \n",
       "22        0.858924            0.483162      0.520181           0.590470   \n",
       "25        0.961657            0.710494      0.694992           0.707516   \n",
       "28        0.664506            0.288494      0.382419           0.328424   \n",
       "30        0.797693            0.637394      0.559487           0.534136   \n",
       "31        0.836174            0.487374      0.565008           0.534065   \n",
       "32        1.084404            0.403472      0.545122           0.605603   \n",
       "33        1.117061            0.416679      0.497369           0.734735   \n",
       "36        1.057918            0.562716      0.613400           0.648119   \n",
       "38        0.770486            0.497955      0.420758           0.580742   \n",
       "40        0.985964            0.562589      0.819742           0.832777   \n",
       "41        1.116735            0.587760      0.512300           0.643933   \n",
       "45        1.082053            0.702005      0.638196           0.774142   \n",
       "46        0.884135            0.489918      0.444371           0.443952   \n",
       "54        0.957026            0.649903      0.782294           0.796070   \n",
       "55        0.960316            0.639667      0.540802           0.466501   \n",
       "57        0.827287            0.628500      0.497393           0.518479   \n",
       "58        0.822971            0.512731      0.459786           0.614442   \n",
       "59        0.777285            0.525944      0.619767           0.587452   \n",
       "60        1.258663            0.493969      0.523541           0.555111   \n",
       "61        1.234840            0.512068      0.506209           0.587186   \n",
       "62        0.994820            0.598696      0.705596           0.616469   \n",
       "63        1.067082            0.513828      0.457517           0.516314   \n",
       "64        0.838911            0.520366      0.460764           0.514700   \n",
       "68        0.858693            0.478229      0.626215           0.684260   \n",
       "73        0.914121            0.536043      0.545856           0.636383   \n",
       "74        0.849195            0.591013      0.691105           0.598684   \n",
       "79        1.009132            0.463156      0.416959           0.465821   \n",
       "84        0.696501            0.327363      0.583804           0.541174   \n",
       "87        0.939058            0.557740      0.716796           0.844498   \n",
       "\n",
       "    N_CC_Anterior  \n",
       "0        0.982338  \n",
       "1        1.151384  \n",
       "2        1.224615  \n",
       "3        1.005833  \n",
       "4        1.045936  \n",
       "5        0.942896  \n",
       "6        0.825341  \n",
       "7        0.993821  \n",
       "8        1.206681  \n",
       "11       0.938209  \n",
       "13       1.128661  \n",
       "16       0.816357  \n",
       "19       1.073273  \n",
       "22       0.923638  \n",
       "25       0.981053  \n",
       "28       0.842900  \n",
       "30       0.906705  \n",
       "31       0.695473  \n",
       "32       1.047977  \n",
       "33       0.923989  \n",
       "36       0.956166  \n",
       "38       0.861083  \n",
       "40       1.068449  \n",
       "41       1.003040  \n",
       "45       1.008612  \n",
       "46       0.917012  \n",
       "54       0.822913  \n",
       "55       0.859107  \n",
       "57       0.671268  \n",
       "58       0.899231  \n",
       "59       0.774397  \n",
       "60       1.215930  \n",
       "61       1.124402  \n",
       "62       0.831331  \n",
       "63       0.825296  \n",
       "64       0.841625  \n",
       "68       0.983302  \n",
       "73       0.917200  \n",
       "74       0.699805  \n",
       "79       0.809734  \n",
       "84       0.754891  \n",
       "87       0.932907  \n",
       "\n",
       "[42 rows x 187 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdd_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_cat = [\n",
    "'Gender',\n",
    "# 'Race',\n",
    "'Ethnicity',\n",
    "'Education',\n",
    "'Employment Status',\n",
    "'Household Income',]\n",
    "\n",
    "demo_cont = ['Height',\n",
    "'Weight',\n",
    "'BMI',\n",
    "'Age',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                        </th><th>   </th><th>Missing  </th><th>Overall    </th><th>F          </th><th>M          </th><th>O         </th><th>P-Value  </th><th>Test                                     </th><th>SMD (F,O)  </th><th>SMD (M,O)  </th><th>SMD (F,M)  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>n                       </td><td>   </td><td>         </td><td>42         </td><td>17         </td><td>24         </td><td>1         </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>Gender, n (%)           </td><td>O  </td><td>0        </td><td>1 (2.4)    </td><td>           </td><td>           </td><td>1 (100.0) </td><td>&lt;0.001   </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\n",
       "<tr><td>                        </td><td>M  </td><td>         </td><td>24 (57.1)  </td><td>           </td><td>24 (100.0) </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>F  </td><td>         </td><td>17 (40.5)  </td><td>17 (100.0) </td><td>           </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>Height, mean (SD)       </td><td>   </td><td>0        </td><td>1.7 (0.1)  </td><td>1.6 (0.1)  </td><td>1.8 (0.1)  </td><td>1.7 (0.0) </td><td>&lt;0.001   </td><td>One-way ANOVA                            </td><td>1.932      </td><td>-1.005     </td><td>1.888      </td></tr>\n",
       "<tr><td>Education, n (%)        </td><td>2.0</td><td>1        </td><td>2 (4.9)    </td><td>           </td><td>2 (8.3)    </td><td>          </td><td>0.014    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\n",
       "<tr><td>                        </td><td>3.0</td><td>         </td><td>2 (4.9)    </td><td>1 (6.2)    </td><td>           </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>4.0</td><td>         </td><td>5 (12.2)   </td><td>2 (12.5)   </td><td>3 (12.5)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>5.0</td><td>         </td><td>4 (9.8)    </td><td>1 (6.2)    </td><td>3 (12.5)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>6.0</td><td>         </td><td>14 (34.1)  </td><td>6 (37.5)   </td><td>8 (33.3)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>7.0</td><td>         </td><td>8 (19.5)   </td><td>2 (12.5)   </td><td>6 (25.0)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>8.0</td><td>         </td><td>6 (14.6)   </td><td>4 (25.0)   </td><td>2 (8.3)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>Age, mean (SD)          </td><td>   </td><td>0        </td><td>38.2 (11.5)</td><td>32.9 (8.3) </td><td>41.4 (12.3)</td><td>51.0 (0.0)</td><td>0.032    </td><td>One-way ANOVA                            </td><td>3.065      </td><td>1.103      </td><td>0.808      </td></tr>\n",
       "<tr><td>Weight, mean (SD)       </td><td>   </td><td>0        </td><td>78.2 (19.7)</td><td>70.1 (20.0)</td><td>83.9 (18.2)</td><td>79.4 (0.0)</td><td>0.087    </td><td>One-way ANOVA                            </td><td>0.653      </td><td>-0.348     </td><td>0.717      </td></tr>\n",
       "<tr><td>Employment Status, n (%)</td><td>3.0</td><td>3        </td><td>11 (28.2)  </td><td>3 (18.8)   </td><td>8 (36.4)   </td><td>          </td><td>0.385    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\n",
       "<tr><td>                        </td><td>1.0</td><td>         </td><td>1 (2.6)    </td><td>           </td><td>1 (4.5)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>0.0</td><td>         </td><td>10 (25.6)  </td><td>3 (18.8)   </td><td>7 (31.8)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>2.0</td><td>         </td><td>17 (43.6)  </td><td>10 (62.5)  </td><td>6 (27.3)   </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>Ethnicity, n (%)        </td><td>1.0</td><td>1        </td><td>6 (14.6)   </td><td>4 (23.5)   </td><td>2 (8.7)    </td><td>          </td><td>0.512    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\n",
       "<tr><td>                        </td><td>2.0</td><td>         </td><td>33 (80.5)  </td><td>13 (76.5)  </td><td>19 (82.6)  </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>3.0</td><td>         </td><td>2 (4.9)    </td><td>           </td><td>2 (8.7)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>Household Income, n (%) </td><td>4.0</td><td>3        </td><td>6 (15.4)   </td><td>3 (18.8)   </td><td>3 (13.6)   </td><td>          </td><td>0.627    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\n",
       "<tr><td>                        </td><td>1.0</td><td>         </td><td>15 (38.5)  </td><td>6 (37.5)   </td><td>8 (36.4)   </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>2.0</td><td>         </td><td>10 (25.6)  </td><td>6 (37.5)   </td><td>4 (18.2)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>3.0</td><td>         </td><td>7 (17.9)   </td><td>1 (6.2)    </td><td>6 (27.3)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>                        </td><td>5.0</td><td>         </td><td>1 (2.6)    </td><td>           </td><td>1 (4.5)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\n",
       "<tr><td>BMI, mean (SD)          </td><td>   </td><td>0        </td><td>25.9 (5.6) </td><td>25.7 (6.2) </td><td>26.1 (5.4) </td><td>26.6 (0.0)</td><td>0.971    </td><td>One-way ANOVA                            </td><td>0.206      </td><td>0.137      </td><td>0.067      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                        </th><th>   </th><th>Missing  </th><th>Overall    </th><th>F          </th><th>M          </th><th>O         </th><th>P-Value  </th><th>Test                                     </th><th>SMD (F,O)  </th><th>SMD (M,O)  </th><th>SMD (F,M)  </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>n                       </td><td>   </td><td>         </td><td>42         </td><td>17         </td><td>24         </td><td>1         </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>Gender, n (%)           </td><td>O  </td><td>0        </td><td>1 (2.4)    </td><td>           </td><td>           </td><td>1 (100.0) </td><td>&lt;0.001   </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\\n<tr><td>                        </td><td>M  </td><td>         </td><td>24 (57.1)  </td><td>           </td><td>24 (100.0) </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>F  </td><td>         </td><td>17 (40.5)  </td><td>17 (100.0) </td><td>           </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>Height, mean (SD)       </td><td>   </td><td>0        </td><td>1.7 (0.1)  </td><td>1.6 (0.1)  </td><td>1.8 (0.1)  </td><td>1.7 (0.0) </td><td>&lt;0.001   </td><td>One-way ANOVA                            </td><td>1.932      </td><td>-1.005     </td><td>1.888      </td></tr>\\n<tr><td>Education, n (%)        </td><td>2.0</td><td>1        </td><td>2 (4.9)    </td><td>           </td><td>2 (8.3)    </td><td>          </td><td>0.014    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\\n<tr><td>                        </td><td>3.0</td><td>         </td><td>2 (4.9)    </td><td>1 (6.2)    </td><td>           </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>4.0</td><td>         </td><td>5 (12.2)   </td><td>2 (12.5)   </td><td>3 (12.5)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>5.0</td><td>         </td><td>4 (9.8)    </td><td>1 (6.2)    </td><td>3 (12.5)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>6.0</td><td>         </td><td>14 (34.1)  </td><td>6 (37.5)   </td><td>8 (33.3)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>7.0</td><td>         </td><td>8 (19.5)   </td><td>2 (12.5)   </td><td>6 (25.0)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>8.0</td><td>         </td><td>6 (14.6)   </td><td>4 (25.0)   </td><td>2 (8.3)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>Age, mean (SD)          </td><td>   </td><td>0        </td><td>38.2 (11.5)</td><td>32.9 (8.3) </td><td>41.4 (12.3)</td><td>51.0 (0.0)</td><td>0.032    </td><td>One-way ANOVA                            </td><td>3.065      </td><td>1.103      </td><td>0.808      </td></tr>\\n<tr><td>Weight, mean (SD)       </td><td>   </td><td>0        </td><td>78.2 (19.7)</td><td>70.1 (20.0)</td><td>83.9 (18.2)</td><td>79.4 (0.0)</td><td>0.087    </td><td>One-way ANOVA                            </td><td>0.653      </td><td>-0.348     </td><td>0.717      </td></tr>\\n<tr><td>Employment Status, n (%)</td><td>3.0</td><td>3        </td><td>11 (28.2)  </td><td>3 (18.8)   </td><td>8 (36.4)   </td><td>          </td><td>0.385    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\\n<tr><td>                        </td><td>1.0</td><td>         </td><td>1 (2.6)    </td><td>           </td><td>1 (4.5)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>0.0</td><td>         </td><td>10 (25.6)  </td><td>3 (18.8)   </td><td>7 (31.8)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>2.0</td><td>         </td><td>17 (43.6)  </td><td>10 (62.5)  </td><td>6 (27.3)   </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>Ethnicity, n (%)        </td><td>1.0</td><td>1        </td><td>6 (14.6)   </td><td>4 (23.5)   </td><td>2 (8.7)    </td><td>          </td><td>0.512    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\\n<tr><td>                        </td><td>2.0</td><td>         </td><td>33 (80.5)  </td><td>13 (76.5)  </td><td>19 (82.6)  </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>3.0</td><td>         </td><td>2 (4.9)    </td><td>           </td><td>2 (8.7)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>Household Income, n (%) </td><td>4.0</td><td>3        </td><td>6 (15.4)   </td><td>3 (18.8)   </td><td>3 (13.6)   </td><td>          </td><td>0.627    </td><td>Chi-squared (warning: expected count &lt; 5)</td><td>nan        </td><td>nan        </td><td>nan        </td></tr>\\n<tr><td>                        </td><td>1.0</td><td>         </td><td>15 (38.5)  </td><td>6 (37.5)   </td><td>8 (36.4)   </td><td>1 (100.0) </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>2.0</td><td>         </td><td>10 (25.6)  </td><td>6 (37.5)   </td><td>4 (18.2)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>3.0</td><td>         </td><td>7 (17.9)   </td><td>1 (6.2)    </td><td>6 (27.3)   </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>                        </td><td>5.0</td><td>         </td><td>1 (2.6)    </td><td>           </td><td>1 (4.5)    </td><td>          </td><td>         </td><td>                                         </td><td>           </td><td>           </td><td>           </td></tr>\\n<tr><td>BMI, mean (SD)          </td><td>   </td><td>0        </td><td>25.9 (5.6) </td><td>25.7 (6.2) </td><td>26.1 (5.4) </td><td>26.6 (0.0)</td><td>0.971    </td><td>One-way ANOVA                            </td><td>0.206      </td><td>0.137      </td><td>0.067      </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tableone\n",
    "table = tableone.TableOne(data=mdd_master, \n",
    "                          categorical = demo_cat,\n",
    "                          groupby='Gender', \n",
    "                          pval=True,\n",
    "                          columns = demo_cat+demo_cont,\n",
    "                          htest_name=True,\n",
    "                          smd = True,\n",
    "                         sort='P-Value', label_suffix=True)\n",
    "\n",
    "table.tabulate(tablefmt=\"html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def cluster_plot(data):\n",
    "    \n",
    "    list_of_features = data.columns\n",
    "    StandardScaler = preprocessing.StandardScaler()\n",
    "    x_scaled = StandardScaler.fit_transform(data)\n",
    "    for n_clusters in range(2,3):\n",
    "        # Create a subplot with 1 row and 2 columns\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(18, 7)\n",
    "\n",
    "        # The 1st subplot is the silhouette plot\n",
    "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "        # lie within [-0.1, 1]\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "        # plots of individual clusters, to demarcate them clearly.\n",
    "        ax1.set_ylim([0, len(x_scaled) + (n_clusters + 1) * 10])\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        #clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "        pca_2d = PCA(n_components=3)\n",
    "        PCs_2d = pca_2d.fit_transform(x_scaled)\n",
    "        #clusterer = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=4)\n",
    "        clusterer = AgglomerativeClustering(n_clusters = n_clusters,compute_full_tree=True)\n",
    "        cluster_labels = clusterer.fit_predict(PCs_2d[:,1:3])\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette = []\n",
    "\n",
    "        silhouette_avg = silhouette_score(x_scaled, cluster_labels)\n",
    "        silhouette.append(silhouette_avg)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(x_scaled, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"Silhouette Coefficient Values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "\n",
    "        #PCA with two principal components so we can dimensionality reduce the clusters found\n",
    "        pca_2d = PCA(n_components=3)\n",
    "        PCs_2d = pd.DataFrame(pca_2d.fit_transform(x_scaled)).to_numpy()\n",
    "        ax2.scatter(PCs_2d[:, 1], PCs_2d[:, 2], marker='.', s=200, lw=0, alpha=0.7,c=colors, edgecolor='k')\n",
    "        '''\n",
    "        # Labeling the clusters\n",
    "        circle_pts = []\n",
    "        unique_clusters = set(cluster_labels)\n",
    "        for item in unique_clusters:\n",
    "            mean_point = PCs_2d[cluster_labels == item].mean(axis=0)\n",
    "            circle_pts.append(mean_point)\n",
    "\n",
    "        # Draw white circles at cluster centers\n",
    "        circle_array = np.array(circle_pts)\n",
    "        ax2.scatter(circle_array[:, 0], circle_array[:, 1], marker='o',\n",
    "                    c=\"white\", alpha=1, s=10**3, edgecolor='k')\n",
    "\n",
    "        for i, c in enumerate(circle_pts):\n",
    "            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                        s=100, edgecolor='k')\n",
    "        '''\n",
    "        ax2.set_title(\"The visualization of the clustered data.\")\n",
    "        ax2.set_xlabel(\"PCA Reduction: Dimension 1\")\n",
    "        ax2.set_ylabel(\"PCA Reduction: Dimension 2\")\n",
    "\n",
    "        plt.suptitle((\"Silhouette analysis: \"\n",
    "                      \" Cluster Number = %d\" % n_clusters),fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "    from matplotlib.pyplot import figure\n",
    "    figure(num=None, figsize=(8, 6), dpi=200, facecolor='w', edgecolor='k')\n",
    "    plt.rcParams['axes.facecolor'] = 'lightgray'\n",
    "\n",
    "\n",
    "    plt.plot(range_n_clusters, \n",
    "             silhouette, \n",
    "             marker='o',\n",
    "             linestyle='--',\n",
    "             alpha=1,)\n",
    "\n",
    "    plt.title(\"Silhouette Value by Cluster\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "def db_plot(data, eps):\n",
    "    '''\n",
    "    x_scaled should be min_max processed\n",
    "    eps should be determined by the plot ouputted in this function\n",
    "    returns cluster assignments\n",
    "    '''\n",
    "    list_of_features = data.columns\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    data[list_of_features] = min_max_scaler.fit_transform(data)\n",
    "    neigh = NearestNeighbors(n_neighbors=2)\n",
    "    nbrs = neigh.fit(x_scaled)\n",
    "    distances, indices = nbrs.kneighbors(x_scaled)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:,1]\n",
    "    plt.plot(distances)\n",
    "    m = DBSCAN(eps=1, min_samples=2)\n",
    "    m.fit(x_scaled)\n",
    "    clusters = m.labels_\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def kmeans_feature_selection(data, n_desired_features, n_clusters=2):\n",
    "    '''\n",
    "    iteratively performs k_means clustering to determine features that would be useful for clustering\n",
    "    n_desired_features = how many features you want\n",
    "    data - non-normalizied data\n",
    "    '''\n",
    "\n",
    "    list_of_features = list(data.columns)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    data[list_of_features] = min_max_scaler.fit_transform(data)\n",
    "#     print(data[list_of_features])\n",
    "    # initialize the feature_counter and total list of features\n",
    "    feature_counter = 0\n",
    "    selected_features = []\n",
    "    while len(selected_features) < n_desired_features:\n",
    "        holder = {}\n",
    "        for current_feature in list_of_features:\n",
    "            clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "            cluster_labels = clusterer.fit_predict(data[[current_feature]+selected_features])\n",
    "            silhouette_avg = silhouette_score(data[[current_feature]+selected_features], cluster_labels)\n",
    "            print(cluster_labels)\n",
    "            holder[current_feature] = silhouette_avg        \n",
    "        # append with the max sillhouette key\n",
    "        max_key = max(holder.items(), key=operator.itemgetter(1))[0]\n",
    "        selected_features.append(max(holder.items(), key=operator.itemgetter(1))[0])\n",
    "        print('max sil value: {}'.format(holder[max_key]))\n",
    "        print(selected_features)\n",
    "        list_of_features.remove(max_key)\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Getting clustering dataset\n",
    "#######################################################\n",
    "droplist=['Status',\"XNAT\", \"Age\",\"Gender\",'Height','Weight',\n",
    "          'BMI','Race','Ethnicity','Education','Employment Status', 'Household Income']\n",
    "spectral_df = mdd_master.drop(droplist,axis=1)\n",
    "#     'Normalized FreeSurfer Amygdala Volumes',\n",
    "#     'Normalized ASHS Hippocampal Subfield Volime',\n",
    "scaler = MinMaxScaler()\n",
    "spectral_df_scaled = scaler.fit_transform(spectral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGbankssts</th>\n",
       "      <th>RGbankssts</th>\n",
       "      <th>LGcaudalanteriorcingulate</th>\n",
       "      <th>RGcaudalanteriorcingulate</th>\n",
       "      <th>LGcaudalmiddlefrontal</th>\n",
       "      <th>RGcaudalmiddlefrontal</th>\n",
       "      <th>LGcuneus</th>\n",
       "      <th>RGcuneus</th>\n",
       "      <th>LGentorhinal</th>\n",
       "      <th>RGentorhinal</th>\n",
       "      <th>...</th>\n",
       "      <th>N_Right-VentralDC</th>\n",
       "      <th>N_Right-vessel</th>\n",
       "      <th>N_Right-choroid-plexus</th>\n",
       "      <th>N_WM-hypointensities</th>\n",
       "      <th>N_Optic-Chiasm</th>\n",
       "      <th>N_CC_Posterior</th>\n",
       "      <th>N_CC_Mid_Posterior</th>\n",
       "      <th>N_CC_Central</th>\n",
       "      <th>N_CC_Mid_Anterior</th>\n",
       "      <th>N_CC_Anterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692037</td>\n",
       "      <td>0.926458</td>\n",
       "      <td>0.873107</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.945153</td>\n",
       "      <td>1.081475</td>\n",
       "      <td>1.071910</td>\n",
       "      <td>1.995308</td>\n",
       "      <td>2.755230</td>\n",
       "      <td>...</td>\n",
       "      <td>3.804401</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.532276</td>\n",
       "      <td>1.894469</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>1.071083</td>\n",
       "      <td>0.342685</td>\n",
       "      <td>0.428260</td>\n",
       "      <td>0.397046</td>\n",
       "      <td>0.982338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.769288</td>\n",
       "      <td>0.672186</td>\n",
       "      <td>0.746320</td>\n",
       "      <td>0.386555</td>\n",
       "      <td>0.904909</td>\n",
       "      <td>0.917148</td>\n",
       "      <td>1.043521</td>\n",
       "      <td>1.058555</td>\n",
       "      <td>2.209610</td>\n",
       "      <td>2.035781</td>\n",
       "      <td>...</td>\n",
       "      <td>3.505706</td>\n",
       "      <td>0.054691</td>\n",
       "      <td>0.707489</td>\n",
       "      <td>2.695649</td>\n",
       "      <td>0.132873</td>\n",
       "      <td>0.918633</td>\n",
       "      <td>0.341327</td>\n",
       "      <td>0.434571</td>\n",
       "      <td>0.477965</td>\n",
       "      <td>1.151384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700487</td>\n",
       "      <td>0.639677</td>\n",
       "      <td>0.571418</td>\n",
       "      <td>0.726768</td>\n",
       "      <td>0.989624</td>\n",
       "      <td>1.027669</td>\n",
       "      <td>1.087187</td>\n",
       "      <td>1.175107</td>\n",
       "      <td>2.032376</td>\n",
       "      <td>2.401985</td>\n",
       "      <td>...</td>\n",
       "      <td>3.607140</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.370024</td>\n",
       "      <td>2.645058</td>\n",
       "      <td>0.190682</td>\n",
       "      <td>1.041461</td>\n",
       "      <td>0.633224</td>\n",
       "      <td>0.542124</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>1.224615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708357</td>\n",
       "      <td>0.908720</td>\n",
       "      <td>0.568597</td>\n",
       "      <td>0.551355</td>\n",
       "      <td>0.774782</td>\n",
       "      <td>0.788512</td>\n",
       "      <td>1.082807</td>\n",
       "      <td>1.475029</td>\n",
       "      <td>2.018647</td>\n",
       "      <td>1.948069</td>\n",
       "      <td>...</td>\n",
       "      <td>3.724191</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.840838</td>\n",
       "      <td>4.193174</td>\n",
       "      <td>0.091664</td>\n",
       "      <td>0.845333</td>\n",
       "      <td>0.539141</td>\n",
       "      <td>0.481499</td>\n",
       "      <td>0.507147</td>\n",
       "      <td>1.005833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.836215</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>0.647992</td>\n",
       "      <td>0.603947</td>\n",
       "      <td>0.824631</td>\n",
       "      <td>0.925841</td>\n",
       "      <td>0.984638</td>\n",
       "      <td>1.150488</td>\n",
       "      <td>1.896828</td>\n",
       "      <td>2.007906</td>\n",
       "      <td>...</td>\n",
       "      <td>3.597112</td>\n",
       "      <td>0.061952</td>\n",
       "      <td>0.627542</td>\n",
       "      <td>1.993024</td>\n",
       "      <td>0.120772</td>\n",
       "      <td>0.928297</td>\n",
       "      <td>0.395101</td>\n",
       "      <td>0.402050</td>\n",
       "      <td>0.427790</td>\n",
       "      <td>1.045936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.728620</td>\n",
       "      <td>0.686920</td>\n",
       "      <td>0.667295</td>\n",
       "      <td>0.630623</td>\n",
       "      <td>0.711153</td>\n",
       "      <td>0.843063</td>\n",
       "      <td>1.221158</td>\n",
       "      <td>0.993051</td>\n",
       "      <td>1.788822</td>\n",
       "      <td>2.198131</td>\n",
       "      <td>...</td>\n",
       "      <td>3.957966</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.540291</td>\n",
       "      <td>1.353151</td>\n",
       "      <td>0.188105</td>\n",
       "      <td>1.192518</td>\n",
       "      <td>0.491164</td>\n",
       "      <td>0.528332</td>\n",
       "      <td>0.494288</td>\n",
       "      <td>0.942896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.789364</td>\n",
       "      <td>0.725552</td>\n",
       "      <td>0.534554</td>\n",
       "      <td>0.542937</td>\n",
       "      <td>0.852594</td>\n",
       "      <td>0.929424</td>\n",
       "      <td>1.163934</td>\n",
       "      <td>1.235867</td>\n",
       "      <td>2.049417</td>\n",
       "      <td>2.455630</td>\n",
       "      <td>...</td>\n",
       "      <td>3.898135</td>\n",
       "      <td>0.088655</td>\n",
       "      <td>0.411647</td>\n",
       "      <td>0.836225</td>\n",
       "      <td>0.079911</td>\n",
       "      <td>0.987209</td>\n",
       "      <td>0.739755</td>\n",
       "      <td>0.506814</td>\n",
       "      <td>0.679660</td>\n",
       "      <td>0.825341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.055743</td>\n",
       "      <td>0.828030</td>\n",
       "      <td>0.524291</td>\n",
       "      <td>0.733029</td>\n",
       "      <td>0.811731</td>\n",
       "      <td>0.908342</td>\n",
       "      <td>1.157681</td>\n",
       "      <td>1.018315</td>\n",
       "      <td>1.615803</td>\n",
       "      <td>2.011552</td>\n",
       "      <td>...</td>\n",
       "      <td>3.432859</td>\n",
       "      <td>0.057682</td>\n",
       "      <td>0.693337</td>\n",
       "      <td>5.674513</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>1.199062</td>\n",
       "      <td>0.374743</td>\n",
       "      <td>0.449960</td>\n",
       "      <td>0.659992</td>\n",
       "      <td>0.993821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.781890</td>\n",
       "      <td>0.729160</td>\n",
       "      <td>0.603173</td>\n",
       "      <td>0.630762</td>\n",
       "      <td>0.955269</td>\n",
       "      <td>0.847379</td>\n",
       "      <td>1.070093</td>\n",
       "      <td>1.243793</td>\n",
       "      <td>2.652565</td>\n",
       "      <td>2.759009</td>\n",
       "      <td>...</td>\n",
       "      <td>3.758795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870250</td>\n",
       "      <td>2.967984</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>1.122694</td>\n",
       "      <td>0.614419</td>\n",
       "      <td>0.618096</td>\n",
       "      <td>0.708469</td>\n",
       "      <td>1.206681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.821998</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.642572</td>\n",
       "      <td>0.577840</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.897753</td>\n",
       "      <td>1.096379</td>\n",
       "      <td>1.061582</td>\n",
       "      <td>2.757447</td>\n",
       "      <td>2.220690</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811041</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>2.294796</td>\n",
       "      <td>0.146332</td>\n",
       "      <td>0.961843</td>\n",
       "      <td>0.482619</td>\n",
       "      <td>0.777922</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>0.938209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.870546</td>\n",
       "      <td>0.887557</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.900129</td>\n",
       "      <td>0.963552</td>\n",
       "      <td>0.898409</td>\n",
       "      <td>1.038306</td>\n",
       "      <td>2.016264</td>\n",
       "      <td>2.205072</td>\n",
       "      <td>...</td>\n",
       "      <td>3.605918</td>\n",
       "      <td>0.108884</td>\n",
       "      <td>0.591281</td>\n",
       "      <td>2.653043</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.847240</td>\n",
       "      <td>0.615748</td>\n",
       "      <td>0.583787</td>\n",
       "      <td>0.494404</td>\n",
       "      <td>1.128661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.646056</td>\n",
       "      <td>0.602880</td>\n",
       "      <td>0.543022</td>\n",
       "      <td>0.579757</td>\n",
       "      <td>0.778417</td>\n",
       "      <td>0.743177</td>\n",
       "      <td>0.940713</td>\n",
       "      <td>0.990078</td>\n",
       "      <td>1.863168</td>\n",
       "      <td>2.152004</td>\n",
       "      <td>...</td>\n",
       "      <td>3.590627</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.441208</td>\n",
       "      <td>8.359756</td>\n",
       "      <td>0.173129</td>\n",
       "      <td>0.794929</td>\n",
       "      <td>0.361183</td>\n",
       "      <td>0.469435</td>\n",
       "      <td>0.509780</td>\n",
       "      <td>0.816357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.710340</td>\n",
       "      <td>0.700034</td>\n",
       "      <td>0.421222</td>\n",
       "      <td>0.650136</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.859042</td>\n",
       "      <td>1.106984</td>\n",
       "      <td>1.182879</td>\n",
       "      <td>1.809758</td>\n",
       "      <td>2.237221</td>\n",
       "      <td>...</td>\n",
       "      <td>4.169538</td>\n",
       "      <td>0.046690</td>\n",
       "      <td>0.477808</td>\n",
       "      <td>2.381470</td>\n",
       "      <td>0.089841</td>\n",
       "      <td>1.062658</td>\n",
       "      <td>0.730325</td>\n",
       "      <td>0.738778</td>\n",
       "      <td>0.706341</td>\n",
       "      <td>1.073273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.650547</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.450667</td>\n",
       "      <td>0.674393</td>\n",
       "      <td>0.699619</td>\n",
       "      <td>0.870550</td>\n",
       "      <td>1.003032</td>\n",
       "      <td>0.943150</td>\n",
       "      <td>1.629887</td>\n",
       "      <td>1.807120</td>\n",
       "      <td>...</td>\n",
       "      <td>3.966572</td>\n",
       "      <td>0.058773</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>3.587062</td>\n",
       "      <td>0.162882</td>\n",
       "      <td>0.858924</td>\n",
       "      <td>0.483162</td>\n",
       "      <td>0.520181</td>\n",
       "      <td>0.590470</td>\n",
       "      <td>0.923638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.751968</td>\n",
       "      <td>0.806951</td>\n",
       "      <td>0.539405</td>\n",
       "      <td>0.760474</td>\n",
       "      <td>1.020197</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>1.269914</td>\n",
       "      <td>1.370752</td>\n",
       "      <td>2.095254</td>\n",
       "      <td>2.063624</td>\n",
       "      <td>...</td>\n",
       "      <td>3.649148</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.454444</td>\n",
       "      <td>4.225318</td>\n",
       "      <td>0.087743</td>\n",
       "      <td>0.961657</td>\n",
       "      <td>0.710494</td>\n",
       "      <td>0.694992</td>\n",
       "      <td>0.707516</td>\n",
       "      <td>0.981053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.890690</td>\n",
       "      <td>0.860309</td>\n",
       "      <td>0.637308</td>\n",
       "      <td>0.751676</td>\n",
       "      <td>1.127673</td>\n",
       "      <td>1.063712</td>\n",
       "      <td>1.266005</td>\n",
       "      <td>1.342683</td>\n",
       "      <td>1.792277</td>\n",
       "      <td>1.636534</td>\n",
       "      <td>...</td>\n",
       "      <td>3.504909</td>\n",
       "      <td>0.026724</td>\n",
       "      <td>0.519555</td>\n",
       "      <td>4.496510</td>\n",
       "      <td>0.137449</td>\n",
       "      <td>0.664506</td>\n",
       "      <td>0.288494</td>\n",
       "      <td>0.382419</td>\n",
       "      <td>0.328424</td>\n",
       "      <td>0.842900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.136300</td>\n",
       "      <td>0.816866</td>\n",
       "      <td>0.496778</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.855981</td>\n",
       "      <td>0.911369</td>\n",
       "      <td>1.189703</td>\n",
       "      <td>1.241613</td>\n",
       "      <td>2.387271</td>\n",
       "      <td>2.630269</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811494</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.572358</td>\n",
       "      <td>2.036600</td>\n",
       "      <td>0.089218</td>\n",
       "      <td>0.797693</td>\n",
       "      <td>0.637394</td>\n",
       "      <td>0.559487</td>\n",
       "      <td>0.534136</td>\n",
       "      <td>0.906705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.943075</td>\n",
       "      <td>0.939281</td>\n",
       "      <td>0.670515</td>\n",
       "      <td>0.393107</td>\n",
       "      <td>0.853310</td>\n",
       "      <td>0.858863</td>\n",
       "      <td>1.297792</td>\n",
       "      <td>1.467557</td>\n",
       "      <td>1.761238</td>\n",
       "      <td>1.560856</td>\n",
       "      <td>...</td>\n",
       "      <td>3.957653</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.391789</td>\n",
       "      <td>3.299343</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.836174</td>\n",
       "      <td>0.487374</td>\n",
       "      <td>0.565008</td>\n",
       "      <td>0.534065</td>\n",
       "      <td>0.695473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.754188</td>\n",
       "      <td>0.808866</td>\n",
       "      <td>0.567509</td>\n",
       "      <td>0.651405</td>\n",
       "      <td>0.993275</td>\n",
       "      <td>1.080784</td>\n",
       "      <td>1.132769</td>\n",
       "      <td>1.634562</td>\n",
       "      <td>1.942912</td>\n",
       "      <td>2.838875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.908508</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.680834</td>\n",
       "      <td>4.487187</td>\n",
       "      <td>0.178177</td>\n",
       "      <td>1.084404</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.545122</td>\n",
       "      <td>0.605603</td>\n",
       "      <td>1.047977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.915859</td>\n",
       "      <td>0.667360</td>\n",
       "      <td>0.335299</td>\n",
       "      <td>0.698992</td>\n",
       "      <td>0.939536</td>\n",
       "      <td>0.796085</td>\n",
       "      <td>1.356299</td>\n",
       "      <td>1.588241</td>\n",
       "      <td>1.702172</td>\n",
       "      <td>2.173559</td>\n",
       "      <td>...</td>\n",
       "      <td>3.586329</td>\n",
       "      <td>0.020861</td>\n",
       "      <td>0.516099</td>\n",
       "      <td>2.241400</td>\n",
       "      <td>0.102350</td>\n",
       "      <td>1.117061</td>\n",
       "      <td>0.416679</td>\n",
       "      <td>0.497369</td>\n",
       "      <td>0.734735</td>\n",
       "      <td>0.923989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.120026</td>\n",
       "      <td>0.928381</td>\n",
       "      <td>0.672054</td>\n",
       "      <td>0.678710</td>\n",
       "      <td>0.995527</td>\n",
       "      <td>1.106360</td>\n",
       "      <td>1.299369</td>\n",
       "      <td>1.359572</td>\n",
       "      <td>2.196592</td>\n",
       "      <td>3.495768</td>\n",
       "      <td>...</td>\n",
       "      <td>3.559510</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.664180</td>\n",
       "      <td>2.072942</td>\n",
       "      <td>0.122719</td>\n",
       "      <td>1.057918</td>\n",
       "      <td>0.562716</td>\n",
       "      <td>0.613400</td>\n",
       "      <td>0.648119</td>\n",
       "      <td>0.956166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.777808</td>\n",
       "      <td>0.901889</td>\n",
       "      <td>0.508522</td>\n",
       "      <td>0.401506</td>\n",
       "      <td>1.093438</td>\n",
       "      <td>0.961183</td>\n",
       "      <td>1.314100</td>\n",
       "      <td>1.836498</td>\n",
       "      <td>2.093784</td>\n",
       "      <td>2.379947</td>\n",
       "      <td>...</td>\n",
       "      <td>3.630624</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.469592</td>\n",
       "      <td>3.036317</td>\n",
       "      <td>0.114849</td>\n",
       "      <td>0.770486</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>0.420758</td>\n",
       "      <td>0.580742</td>\n",
       "      <td>0.861083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.830737</td>\n",
       "      <td>0.795593</td>\n",
       "      <td>0.565066</td>\n",
       "      <td>0.756168</td>\n",
       "      <td>0.911123</td>\n",
       "      <td>1.029870</td>\n",
       "      <td>0.941491</td>\n",
       "      <td>0.920763</td>\n",
       "      <td>2.278580</td>\n",
       "      <td>2.333979</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105072</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.388754</td>\n",
       "      <td>0.929132</td>\n",
       "      <td>0.097189</td>\n",
       "      <td>0.985964</td>\n",
       "      <td>0.562589</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.832777</td>\n",
       "      <td>1.068449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.710677</td>\n",
       "      <td>0.873371</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.814504</td>\n",
       "      <td>0.951771</td>\n",
       "      <td>1.029310</td>\n",
       "      <td>1.183728</td>\n",
       "      <td>1.131486</td>\n",
       "      <td>2.729023</td>\n",
       "      <td>2.467255</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162398</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.398774</td>\n",
       "      <td>2.048358</td>\n",
       "      <td>0.071164</td>\n",
       "      <td>1.116735</td>\n",
       "      <td>0.587760</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.643933</td>\n",
       "      <td>1.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.975494</td>\n",
       "      <td>0.710184</td>\n",
       "      <td>0.487489</td>\n",
       "      <td>0.667801</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.882213</td>\n",
       "      <td>1.188695</td>\n",
       "      <td>1.353142</td>\n",
       "      <td>2.290944</td>\n",
       "      <td>2.366704</td>\n",
       "      <td>...</td>\n",
       "      <td>3.596912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513085</td>\n",
       "      <td>1.773324</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>1.082053</td>\n",
       "      <td>0.702005</td>\n",
       "      <td>0.638196</td>\n",
       "      <td>0.774142</td>\n",
       "      <td>1.008612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.743612</td>\n",
       "      <td>0.704965</td>\n",
       "      <td>0.629594</td>\n",
       "      <td>0.655793</td>\n",
       "      <td>0.739307</td>\n",
       "      <td>0.828037</td>\n",
       "      <td>1.243325</td>\n",
       "      <td>1.400776</td>\n",
       "      <td>1.931394</td>\n",
       "      <td>1.881199</td>\n",
       "      <td>...</td>\n",
       "      <td>3.616011</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.467825</td>\n",
       "      <td>2.933539</td>\n",
       "      <td>0.101669</td>\n",
       "      <td>0.884135</td>\n",
       "      <td>0.489918</td>\n",
       "      <td>0.444371</td>\n",
       "      <td>0.443952</td>\n",
       "      <td>0.917012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.706252</td>\n",
       "      <td>0.713809</td>\n",
       "      <td>0.507858</td>\n",
       "      <td>0.484978</td>\n",
       "      <td>1.062899</td>\n",
       "      <td>0.969122</td>\n",
       "      <td>0.976326</td>\n",
       "      <td>1.000356</td>\n",
       "      <td>1.785865</td>\n",
       "      <td>1.866523</td>\n",
       "      <td>...</td>\n",
       "      <td>4.187495</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.514675</td>\n",
       "      <td>2.260984</td>\n",
       "      <td>0.081035</td>\n",
       "      <td>0.957026</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.782294</td>\n",
       "      <td>0.796070</td>\n",
       "      <td>0.822913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.181020</td>\n",
       "      <td>0.958430</td>\n",
       "      <td>0.740910</td>\n",
       "      <td>0.708517</td>\n",
       "      <td>0.829633</td>\n",
       "      <td>0.992080</td>\n",
       "      <td>1.132608</td>\n",
       "      <td>1.244190</td>\n",
       "      <td>2.269478</td>\n",
       "      <td>2.469734</td>\n",
       "      <td>...</td>\n",
       "      <td>3.576572</td>\n",
       "      <td>0.113848</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>3.382715</td>\n",
       "      <td>0.063906</td>\n",
       "      <td>0.960316</td>\n",
       "      <td>0.639667</td>\n",
       "      <td>0.540802</td>\n",
       "      <td>0.466501</td>\n",
       "      <td>0.859107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.030316</td>\n",
       "      <td>0.880605</td>\n",
       "      <td>0.715075</td>\n",
       "      <td>0.774961</td>\n",
       "      <td>1.099456</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>1.316811</td>\n",
       "      <td>1.477366</td>\n",
       "      <td>2.025723</td>\n",
       "      <td>1.936975</td>\n",
       "      <td>...</td>\n",
       "      <td>3.711145</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>0.550193</td>\n",
       "      <td>1.504507</td>\n",
       "      <td>0.145647</td>\n",
       "      <td>0.827287</td>\n",
       "      <td>0.628500</td>\n",
       "      <td>0.497393</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>0.671268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.147754</td>\n",
       "      <td>1.012492</td>\n",
       "      <td>0.471496</td>\n",
       "      <td>0.911739</td>\n",
       "      <td>1.011281</td>\n",
       "      <td>1.204184</td>\n",
       "      <td>1.364922</td>\n",
       "      <td>1.457168</td>\n",
       "      <td>1.988887</td>\n",
       "      <td>2.194201</td>\n",
       "      <td>...</td>\n",
       "      <td>3.560604</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.653454</td>\n",
       "      <td>2.129043</td>\n",
       "      <td>0.074309</td>\n",
       "      <td>0.822971</td>\n",
       "      <td>0.512731</td>\n",
       "      <td>0.459786</td>\n",
       "      <td>0.614442</td>\n",
       "      <td>0.899231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.004578</td>\n",
       "      <td>0.944523</td>\n",
       "      <td>0.616284</td>\n",
       "      <td>0.547118</td>\n",
       "      <td>1.086845</td>\n",
       "      <td>1.173948</td>\n",
       "      <td>1.559186</td>\n",
       "      <td>1.763006</td>\n",
       "      <td>2.237517</td>\n",
       "      <td>1.328172</td>\n",
       "      <td>...</td>\n",
       "      <td>3.441816</td>\n",
       "      <td>0.044024</td>\n",
       "      <td>0.322060</td>\n",
       "      <td>4.746918</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.777285</td>\n",
       "      <td>0.525944</td>\n",
       "      <td>0.619767</td>\n",
       "      <td>0.587452</td>\n",
       "      <td>0.774397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.721423</td>\n",
       "      <td>0.829438</td>\n",
       "      <td>0.509493</td>\n",
       "      <td>0.578848</td>\n",
       "      <td>0.804145</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.961745</td>\n",
       "      <td>1.131748</td>\n",
       "      <td>1.498549</td>\n",
       "      <td>1.727985</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211715</td>\n",
       "      <td>0.040151</td>\n",
       "      <td>0.396425</td>\n",
       "      <td>6.708483</td>\n",
       "      <td>0.098544</td>\n",
       "      <td>1.258663</td>\n",
       "      <td>0.493969</td>\n",
       "      <td>0.523541</td>\n",
       "      <td>0.555111</td>\n",
       "      <td>1.215930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.569649</td>\n",
       "      <td>0.687982</td>\n",
       "      <td>0.628913</td>\n",
       "      <td>0.640061</td>\n",
       "      <td>0.836360</td>\n",
       "      <td>0.850292</td>\n",
       "      <td>1.065104</td>\n",
       "      <td>1.531888</td>\n",
       "      <td>1.911608</td>\n",
       "      <td>1.638121</td>\n",
       "      <td>...</td>\n",
       "      <td>3.837258</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>0.406188</td>\n",
       "      <td>4.557100</td>\n",
       "      <td>0.137783</td>\n",
       "      <td>1.234840</td>\n",
       "      <td>0.512068</td>\n",
       "      <td>0.506209</td>\n",
       "      <td>0.587186</td>\n",
       "      <td>1.124402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.766646</td>\n",
       "      <td>0.920999</td>\n",
       "      <td>0.530481</td>\n",
       "      <td>0.637128</td>\n",
       "      <td>0.738088</td>\n",
       "      <td>0.772042</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>1.058487</td>\n",
       "      <td>2.163959</td>\n",
       "      <td>2.269082</td>\n",
       "      <td>...</td>\n",
       "      <td>3.755489</td>\n",
       "      <td>0.024316</td>\n",
       "      <td>0.466596</td>\n",
       "      <td>3.017353</td>\n",
       "      <td>0.213713</td>\n",
       "      <td>0.994820</td>\n",
       "      <td>0.598696</td>\n",
       "      <td>0.705596</td>\n",
       "      <td>0.616469</td>\n",
       "      <td>0.831331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.108702</td>\n",
       "      <td>0.686024</td>\n",
       "      <td>0.583594</td>\n",
       "      <td>0.779562</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>0.992076</td>\n",
       "      <td>1.262554</td>\n",
       "      <td>1.198468</td>\n",
       "      <td>1.629996</td>\n",
       "      <td>1.669714</td>\n",
       "      <td>...</td>\n",
       "      <td>3.860695</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.434204</td>\n",
       "      <td>2.612509</td>\n",
       "      <td>0.251729</td>\n",
       "      <td>1.067082</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.457517</td>\n",
       "      <td>0.516314</td>\n",
       "      <td>0.825296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.960193</td>\n",
       "      <td>0.639484</td>\n",
       "      <td>0.624142</td>\n",
       "      <td>0.660277</td>\n",
       "      <td>0.751797</td>\n",
       "      <td>0.906364</td>\n",
       "      <td>1.120845</td>\n",
       "      <td>1.102279</td>\n",
       "      <td>2.212913</td>\n",
       "      <td>2.394993</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305261</td>\n",
       "      <td>0.037768</td>\n",
       "      <td>0.490034</td>\n",
       "      <td>1.924255</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>0.838911</td>\n",
       "      <td>0.520366</td>\n",
       "      <td>0.460764</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>0.841625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.788612</td>\n",
       "      <td>1.003723</td>\n",
       "      <td>0.297273</td>\n",
       "      <td>0.361453</td>\n",
       "      <td>1.011823</td>\n",
       "      <td>0.995758</td>\n",
       "      <td>1.139478</td>\n",
       "      <td>1.506970</td>\n",
       "      <td>2.317690</td>\n",
       "      <td>2.462514</td>\n",
       "      <td>...</td>\n",
       "      <td>3.367612</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.375511</td>\n",
       "      <td>2.657202</td>\n",
       "      <td>0.057649</td>\n",
       "      <td>0.858693</td>\n",
       "      <td>0.478229</td>\n",
       "      <td>0.626215</td>\n",
       "      <td>0.684260</td>\n",
       "      <td>0.983302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.992536</td>\n",
       "      <td>0.761637</td>\n",
       "      <td>0.636124</td>\n",
       "      <td>0.820246</td>\n",
       "      <td>1.132787</td>\n",
       "      <td>1.144614</td>\n",
       "      <td>1.166716</td>\n",
       "      <td>1.170828</td>\n",
       "      <td>1.948610</td>\n",
       "      <td>2.205243</td>\n",
       "      <td>...</td>\n",
       "      <td>3.654947</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.417136</td>\n",
       "      <td>2.295790</td>\n",
       "      <td>0.174801</td>\n",
       "      <td>0.914121</td>\n",
       "      <td>0.536043</td>\n",
       "      <td>0.545856</td>\n",
       "      <td>0.636383</td>\n",
       "      <td>0.917200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.765434</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.368965</td>\n",
       "      <td>0.840159</td>\n",
       "      <td>0.785926</td>\n",
       "      <td>0.945252</td>\n",
       "      <td>1.244886</td>\n",
       "      <td>1.329507</td>\n",
       "      <td>2.262626</td>\n",
       "      <td>3.367980</td>\n",
       "      <td>...</td>\n",
       "      <td>3.656367</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.406544</td>\n",
       "      <td>3.050013</td>\n",
       "      <td>0.113843</td>\n",
       "      <td>0.849195</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>0.691105</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.699805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.766493</td>\n",
       "      <td>0.648049</td>\n",
       "      <td>0.731403</td>\n",
       "      <td>0.681152</td>\n",
       "      <td>0.874072</td>\n",
       "      <td>0.956753</td>\n",
       "      <td>1.477787</td>\n",
       "      <td>1.662121</td>\n",
       "      <td>1.514744</td>\n",
       "      <td>1.854056</td>\n",
       "      <td>...</td>\n",
       "      <td>4.055184</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.645477</td>\n",
       "      <td>7.718679</td>\n",
       "      <td>0.148265</td>\n",
       "      <td>1.009132</td>\n",
       "      <td>0.463156</td>\n",
       "      <td>0.416959</td>\n",
       "      <td>0.465821</td>\n",
       "      <td>0.809734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.911179</td>\n",
       "      <td>0.757175</td>\n",
       "      <td>0.728819</td>\n",
       "      <td>0.752977</td>\n",
       "      <td>1.026528</td>\n",
       "      <td>1.200368</td>\n",
       "      <td>1.017399</td>\n",
       "      <td>1.079707</td>\n",
       "      <td>2.842303</td>\n",
       "      <td>2.676840</td>\n",
       "      <td>...</td>\n",
       "      <td>3.641629</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.446421</td>\n",
       "      <td>1.829644</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.696501</td>\n",
       "      <td>0.327363</td>\n",
       "      <td>0.583804</td>\n",
       "      <td>0.541174</td>\n",
       "      <td>0.754891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>0.559610</td>\n",
       "      <td>0.764796</td>\n",
       "      <td>0.921716</td>\n",
       "      <td>0.954612</td>\n",
       "      <td>1.217615</td>\n",
       "      <td>1.177100</td>\n",
       "      <td>2.475931</td>\n",
       "      <td>2.424345</td>\n",
       "      <td>...</td>\n",
       "      <td>3.847024</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.381319</td>\n",
       "      <td>0.675023</td>\n",
       "      <td>0.075510</td>\n",
       "      <td>0.939058</td>\n",
       "      <td>0.557740</td>\n",
       "      <td>0.716796</td>\n",
       "      <td>0.844498</td>\n",
       "      <td>0.932907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LGbankssts  RGbankssts  LGcaudalanteriorcingulate  \\\n",
       "0     0.692037    0.926458                   0.873107   \n",
       "1     0.769288    0.672186                   0.746320   \n",
       "2     0.700487    0.639677                   0.571418   \n",
       "3     0.708357    0.908720                   0.568597   \n",
       "4     0.836215    0.820591                   0.647992   \n",
       "5     0.728620    0.686920                   0.667295   \n",
       "6     0.789364    0.725552                   0.534554   \n",
       "7     1.055743    0.828030                   0.524291   \n",
       "8     0.781890    0.729160                   0.603173   \n",
       "11    0.821998    0.679218                   0.642572   \n",
       "13    0.870546    0.887557                   0.716463   \n",
       "16    0.646056    0.602880                   0.543022   \n",
       "19    0.710340    0.700034                   0.421222   \n",
       "22    0.650547    0.612613                   0.450667   \n",
       "25    0.751968    0.806951                   0.539405   \n",
       "28    0.890690    0.860309                   0.637308   \n",
       "30    1.136300    0.816866                   0.496778   \n",
       "31    0.943075    0.939281                   0.670515   \n",
       "32    0.754188    0.808866                   0.567509   \n",
       "33    0.915859    0.667360                   0.335299   \n",
       "36    1.120026    0.928381                   0.672054   \n",
       "38    0.777808    0.901889                   0.508522   \n",
       "40    0.830737    0.795593                   0.565066   \n",
       "41    0.710677    0.873371                   0.637384   \n",
       "45    0.975494    0.710184                   0.487489   \n",
       "46    0.743612    0.704965                   0.629594   \n",
       "54    0.706252    0.713809                   0.507858   \n",
       "55    1.181020    0.958430                   0.740910   \n",
       "57    1.030316    0.880605                   0.715075   \n",
       "58    1.147754    1.012492                   0.471496   \n",
       "59    1.004578    0.944523                   0.616284   \n",
       "60    0.721423    0.829438                   0.509493   \n",
       "61    0.569649    0.687982                   0.628913   \n",
       "62    0.766646    0.920999                   0.530481   \n",
       "63    1.108702    0.686024                   0.583594   \n",
       "64    0.960193    0.639484                   0.624142   \n",
       "68    0.788612    1.003723                   0.297273   \n",
       "73    0.992536    0.761637                   0.636124   \n",
       "74    0.765434    0.768694                   0.368965   \n",
       "79    0.766493    0.648049                   0.731403   \n",
       "84    0.911179    0.757175                   0.728819   \n",
       "87    0.810032    0.785205                   0.559610   \n",
       "\n",
       "    RGcaudalanteriorcingulate  LGcaudalmiddlefrontal  RGcaudalmiddlefrontal  \\\n",
       "0                    0.656190               0.999534               0.945153   \n",
       "1                    0.386555               0.904909               0.917148   \n",
       "2                    0.726768               0.989624               1.027669   \n",
       "3                    0.551355               0.774782               0.788512   \n",
       "4                    0.603947               0.824631               0.925841   \n",
       "5                    0.630623               0.711153               0.843063   \n",
       "6                    0.542937               0.852594               0.929424   \n",
       "7                    0.733029               0.811731               0.908342   \n",
       "8                    0.630762               0.955269               0.847379   \n",
       "11                   0.577840               0.988026               0.897753   \n",
       "13                   0.595669               0.900129               0.963552   \n",
       "16                   0.579757               0.778417               0.743177   \n",
       "19                   0.650136               0.881000               0.859042   \n",
       "22                   0.674393               0.699619               0.870550   \n",
       "25                   0.760474               1.020197               0.998588   \n",
       "28                   0.751676               1.127673               1.063712   \n",
       "30                   0.791767               0.855981               0.911369   \n",
       "31                   0.393107               0.853310               0.858863   \n",
       "32                   0.651405               0.993275               1.080784   \n",
       "33                   0.698992               0.939536               0.796085   \n",
       "36                   0.678710               0.995527               1.106360   \n",
       "38                   0.401506               1.093438               0.961183   \n",
       "40                   0.756168               0.911123               1.029870   \n",
       "41                   0.814504               0.951771               1.029310   \n",
       "45                   0.667801               0.900156               0.882213   \n",
       "46                   0.655793               0.739307               0.828037   \n",
       "54                   0.484978               1.062899               0.969122   \n",
       "55                   0.708517               0.829633               0.992080   \n",
       "57                   0.774961               1.099456               0.992158   \n",
       "58                   0.911739               1.011281               1.204184   \n",
       "59                   0.547118               1.086845               1.173948   \n",
       "60                   0.578848               0.804145               0.890713   \n",
       "61                   0.640061               0.836360               0.850292   \n",
       "62                   0.637128               0.738088               0.772042   \n",
       "63                   0.779562               0.908978               0.992076   \n",
       "64                   0.660277               0.751797               0.906364   \n",
       "68                   0.361453               1.011823               0.995758   \n",
       "73                   0.820246               1.132787               1.144614   \n",
       "74                   0.840159               0.785926               0.945252   \n",
       "79                   0.681152               0.874072               0.956753   \n",
       "84                   0.752977               1.026528               1.200368   \n",
       "87                   0.764796               0.921716               0.954612   \n",
       "\n",
       "    LGcuneus  RGcuneus  LGentorhinal  RGentorhinal  ...  N_Right-VentralDC  \\\n",
       "0   1.081475  1.071910      1.995308      2.755230  ...           3.804401   \n",
       "1   1.043521  1.058555      2.209610      2.035781  ...           3.505706   \n",
       "2   1.087187  1.175107      2.032376      2.401985  ...           3.607140   \n",
       "3   1.082807  1.475029      2.018647      1.948069  ...           3.724191   \n",
       "4   0.984638  1.150488      1.896828      2.007906  ...           3.597112   \n",
       "5   1.221158  0.993051      1.788822      2.198131  ...           3.957966   \n",
       "6   1.163934  1.235867      2.049417      2.455630  ...           3.898135   \n",
       "7   1.157681  1.018315      1.615803      2.011552  ...           3.432859   \n",
       "8   1.070093  1.243793      2.652565      2.759009  ...           3.758795   \n",
       "11  1.096379  1.061582      2.757447      2.220690  ...           3.811041   \n",
       "13  0.898409  1.038306      2.016264      2.205072  ...           3.605918   \n",
       "16  0.940713  0.990078      1.863168      2.152004  ...           3.590627   \n",
       "19  1.106984  1.182879      1.809758      2.237221  ...           4.169538   \n",
       "22  1.003032  0.943150      1.629887      1.807120  ...           3.966572   \n",
       "25  1.269914  1.370752      2.095254      2.063624  ...           3.649148   \n",
       "28  1.266005  1.342683      1.792277      1.636534  ...           3.504909   \n",
       "30  1.189703  1.241613      2.387271      2.630269  ...           3.811494   \n",
       "31  1.297792  1.467557      1.761238      1.560856  ...           3.957653   \n",
       "32  1.132769  1.634562      1.942912      2.838875  ...           3.908508   \n",
       "33  1.356299  1.588241      1.702172      2.173559  ...           3.586329   \n",
       "36  1.299369  1.359572      2.196592      3.495768  ...           3.559510   \n",
       "38  1.314100  1.836498      2.093784      2.379947  ...           3.630624   \n",
       "40  0.941491  0.920763      2.278580      2.333979  ...           4.105072   \n",
       "41  1.183728  1.131486      2.729023      2.467255  ...           3.162398   \n",
       "45  1.188695  1.353142      2.290944      2.366704  ...           3.596912   \n",
       "46  1.243325  1.400776      1.931394      1.881199  ...           3.616011   \n",
       "54  0.976326  1.000356      1.785865      1.866523  ...           4.187495   \n",
       "55  1.132608  1.244190      2.269478      2.469734  ...           3.576572   \n",
       "57  1.316811  1.477366      2.025723      1.936975  ...           3.711145   \n",
       "58  1.364922  1.457168      1.988887      2.194201  ...           3.560604   \n",
       "59  1.559186  1.763006      2.237517      1.328172  ...           3.441816   \n",
       "60  0.961745  1.131748      1.498549      1.727985  ...           3.211715   \n",
       "61  1.065104  1.531888      1.911608      1.638121  ...           3.837258   \n",
       "62  0.969707  1.058487      2.163959      2.269082  ...           3.755489   \n",
       "63  1.262554  1.198468      1.629996      1.669714  ...           3.860695   \n",
       "64  1.120845  1.102279      2.212913      2.394993  ...           4.305261   \n",
       "68  1.139478  1.506970      2.317690      2.462514  ...           3.367612   \n",
       "73  1.166716  1.170828      1.948610      2.205243  ...           3.654947   \n",
       "74  1.244886  1.329507      2.262626      3.367980  ...           3.656367   \n",
       "79  1.477787  1.662121      1.514744      1.854056  ...           4.055184   \n",
       "84  1.017399  1.079707      2.842303      2.676840  ...           3.641629   \n",
       "87  1.217615  1.177100      2.475931      2.424345  ...           3.847024   \n",
       "\n",
       "    N_Right-vessel  N_Right-choroid-plexus  N_WM-hypointensities  \\\n",
       "0         0.025932                0.532276              1.894469   \n",
       "1         0.054691                0.707489              2.695649   \n",
       "2         0.012102                0.370024              2.645058   \n",
       "3         0.017628                0.840838              4.193174   \n",
       "4         0.061952                0.627542              1.993024   \n",
       "5         0.013144                0.540291              1.353151   \n",
       "6         0.088655                0.411647              0.836225   \n",
       "7         0.057682                0.693337              5.674513   \n",
       "8         0.000000                0.870250              2.967984   \n",
       "11        0.002389                0.537179              2.294796   \n",
       "13        0.108884                0.591281              2.653043   \n",
       "16        0.004064                0.441208              8.359756   \n",
       "19        0.046690                0.477808              2.381470   \n",
       "22        0.058773                0.363971              3.587062   \n",
       "25        0.014586                0.454444              4.225318   \n",
       "28        0.026724                0.519555              4.496510   \n",
       "30        0.022329                0.572358              2.036600   \n",
       "31        0.005826                0.391789              3.299343   \n",
       "32        0.006335                0.680834              4.487187   \n",
       "33        0.020861                0.516099              2.241400   \n",
       "36        0.037219                0.664180              2.072942   \n",
       "38        0.022690                0.469592              3.036317   \n",
       "40        0.031284                0.388754              0.929132   \n",
       "41        0.015749                0.398774              2.048358   \n",
       "45        0.000000                0.513085              1.773324   \n",
       "46        0.008481                0.467825              2.933539   \n",
       "54        0.060067                0.514675              2.260984   \n",
       "55        0.113848                0.559046              3.382715   \n",
       "57        0.028568                0.550193              1.504507   \n",
       "58        0.009846                0.653454              2.129043   \n",
       "59        0.044024                0.322060              4.746918   \n",
       "60        0.040151                0.396425              6.708483   \n",
       "61        0.044680                0.406188              4.557100   \n",
       "62        0.024316                0.466596              3.017353   \n",
       "63        0.110651                0.434204              2.612509   \n",
       "64        0.037768                0.490034              1.924255   \n",
       "68        0.010004                0.375511              2.657202   \n",
       "73        0.026841                0.417136              2.295790   \n",
       "74        0.027689                0.406544              3.050013   \n",
       "79        0.001382                0.645477              7.718679   \n",
       "84        0.022027                0.446421              1.829644   \n",
       "87        0.008732                0.381319              0.675023   \n",
       "\n",
       "    N_Optic-Chiasm  N_CC_Posterior  N_CC_Mid_Posterior  N_CC_Central  \\\n",
       "0         0.092779        1.071083            0.342685      0.428260   \n",
       "1         0.132873        0.918633            0.341327      0.434571   \n",
       "2         0.190682        1.041461            0.633224      0.542124   \n",
       "3         0.091664        0.845333            0.539141      0.481499   \n",
       "4         0.120772        0.928297            0.395101      0.402050   \n",
       "5         0.188105        1.192518            0.491164      0.528332   \n",
       "6         0.079911        0.987209            0.739755      0.506814   \n",
       "7         0.052029        1.199062            0.374743      0.449960   \n",
       "8         0.129657        1.122694            0.614419      0.618096   \n",
       "11        0.146332        0.961843            0.482619      0.777922   \n",
       "13        0.102113        0.847240            0.615748      0.583787   \n",
       "16        0.173129        0.794929            0.361183      0.469435   \n",
       "19        0.089841        1.062658            0.730325      0.738778   \n",
       "22        0.162882        0.858924            0.483162      0.520181   \n",
       "25        0.087743        0.961657            0.710494      0.694992   \n",
       "28        0.137449        0.664506            0.288494      0.382419   \n",
       "30        0.089218        0.797693            0.637394      0.559487   \n",
       "31        0.027872        0.836174            0.487374      0.565008   \n",
       "32        0.178177        1.084404            0.403472      0.545122   \n",
       "33        0.102350        1.117061            0.416679      0.497369   \n",
       "36        0.122719        1.057918            0.562716      0.613400   \n",
       "38        0.114849        0.770486            0.497955      0.420758   \n",
       "40        0.097189        0.985964            0.562589      0.819742   \n",
       "41        0.071164        1.116735            0.587760      0.512300   \n",
       "45        0.065014        1.082053            0.702005      0.638196   \n",
       "46        0.101669        0.884135            0.489918      0.444371   \n",
       "54        0.081035        0.957026            0.649903      0.782294   \n",
       "55        0.063906        0.960316            0.639667      0.540802   \n",
       "57        0.145647        0.827287            0.628500      0.497393   \n",
       "58        0.074309        0.822971            0.512731      0.459786   \n",
       "59        0.130900        0.777285            0.525944      0.619767   \n",
       "60        0.098544        1.258663            0.493969      0.523541   \n",
       "61        0.137783        1.234840            0.512068      0.506209   \n",
       "62        0.213713        0.994820            0.598696      0.705596   \n",
       "63        0.251729        1.067082            0.513828      0.457517   \n",
       "64        0.195683        0.838911            0.520366      0.460764   \n",
       "68        0.057649        0.858693            0.478229      0.626215   \n",
       "73        0.174801        0.914121            0.536043      0.545856   \n",
       "74        0.113843        0.849195            0.591013      0.691105   \n",
       "79        0.148265        1.009132            0.463156      0.416959   \n",
       "84        0.069783        0.696501            0.327363      0.583804   \n",
       "87        0.075510        0.939058            0.557740      0.716796   \n",
       "\n",
       "    N_CC_Mid_Anterior  N_CC_Anterior  \n",
       "0            0.397046       0.982338  \n",
       "1            0.477965       1.151384  \n",
       "2            0.558800       1.224615  \n",
       "3            0.507147       1.005833  \n",
       "4            0.427790       1.045936  \n",
       "5            0.494288       0.942896  \n",
       "6            0.679660       0.825341  \n",
       "7            0.659992       0.993821  \n",
       "8            0.708469       1.206681  \n",
       "11           0.734048       0.938209  \n",
       "13           0.494404       1.128661  \n",
       "16           0.509780       0.816357  \n",
       "19           0.706341       1.073273  \n",
       "22           0.590470       0.923638  \n",
       "25           0.707516       0.981053  \n",
       "28           0.328424       0.842900  \n",
       "30           0.534136       0.906705  \n",
       "31           0.534065       0.695473  \n",
       "32           0.605603       1.047977  \n",
       "33           0.734735       0.923989  \n",
       "36           0.648119       0.956166  \n",
       "38           0.580742       0.861083  \n",
       "40           0.832777       1.068449  \n",
       "41           0.643933       1.003040  \n",
       "45           0.774142       1.008612  \n",
       "46           0.443952       0.917012  \n",
       "54           0.796070       0.822913  \n",
       "55           0.466501       0.859107  \n",
       "57           0.518479       0.671268  \n",
       "58           0.614442       0.899231  \n",
       "59           0.587452       0.774397  \n",
       "60           0.555111       1.215930  \n",
       "61           0.587186       1.124402  \n",
       "62           0.616469       0.831331  \n",
       "63           0.516314       0.825296  \n",
       "64           0.514700       0.841625  \n",
       "68           0.684260       0.983302  \n",
       "73           0.636383       0.917200  \n",
       "74           0.598684       0.699805  \n",
       "79           0.465821       0.809734  \n",
       "84           0.541174       0.754891  \n",
       "87           0.844498       0.932907  \n",
       "\n",
       "[42 rows x 175 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.018524146588984096\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "# Clustering\n",
    "#######################################################\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "import numpy as np\n",
    "for_df = []\n",
    "# for k in range(2,8):\n",
    "#     clustering = SpectralClustering(n_clusters=k, assign_labels=\"discretize\", random_state=0).fit(spectral_df_scaled)\n",
    "#     results_int = internalValidation(spectral_df_scaled, clustering.labels_)\n",
    "#     results_int['clusters'] = k\n",
    "#     for_df.append(results_int)\n",
    "#     print(results_int)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(spectral_df)\n",
    "X=scaler.transform(spectral_df)\n",
    "\n",
    "pca_2d = PCA(n_components=3)\n",
    "PCs_2d = pca_2d.fit_transform(X)\n",
    "\n",
    "#Spectral Clustering:\n",
    "#clustering = SpectralClustering(n_clusters=2, assign_labels=\"discretize\", random_state=4).fit(PCs_2d[:,2:4])\n",
    "\n",
    "#HC:\n",
    "clustering = AgglomerativeClustering(n_clusters = 2,compute_full_tree=True).fit(PCs_2d[:,1:3])\n",
    "\n",
    "\n",
    "#clustered = mdd_master\n",
    "clustered = df#.iloc[spectral_df.index]\n",
    "clustered['cluster'] = clustering.labels_\n",
    "'''\n",
    "newcols = []\n",
    "for item in clustered.columns: \n",
    "    newcols.append(item[0]+' '+item[1])\n",
    "clustered.columns = newcols\n",
    "'''\n",
    "cluster_plot(spectral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Imaging metrics\n",
    "#######################################################\n",
    "\n",
    "import tableone\n",
    "clustered['cluster'] = clustering.labels_\n",
    "dataSN=clustered.drop('XNAT',axis=1)\n",
    "table = tableone.TableOne(data=dataSN, \n",
    "                          groupby='cluster', \n",
    "                          pval=True,\n",
    "                         htest_name=True,\n",
    "                         sort='P-Value', label_suffix=True)\n",
    "\n",
    "table.tabulate(tablefmt=\"html\")\n",
    "table.to_excel('PC2vsPC3_HC.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                        </th><th>   </th><th>Missing  </th><th>Overall    </th><th>0          </th><th>1          </th><th>P-Value  </th><th>Test                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>n                       </td><td>   </td><td>         </td><td>42         </td><td>26         </td><td>16         </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>Height, mean (SD)       </td><td>   </td><td>0        </td><td>1.7 (0.1)  </td><td>1.8 (0.1)  </td><td>1.7 (0.1)  </td><td>0.055    </td><td>Two Sample T-test                        </td></tr>\n",
       "<tr><td>Race, mean (SD)         </td><td>   </td><td>0        </td><td>4.6 (1.2)  </td><td>4.9 (1.0)  </td><td>4.1 (1.4)  </td><td>0.064    </td><td>Two Sample T-test                        </td></tr>\n",
       "<tr><td>Gender, n (%)           </td><td>O  </td><td>0        </td><td>1 (2.4)    </td><td>           </td><td>1 (6.2)    </td><td>0.084    </td><td>Chi-squared (warning: expected count &lt; 5)</td></tr>\n",
       "<tr><td>                        </td><td>M  </td><td>         </td><td>24 (57.1)  </td><td>18 (69.2)  </td><td>6 (37.5)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>                        </td><td>F  </td><td>         </td><td>17 (40.5)  </td><td>8 (30.8)   </td><td>9 (56.2)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>Weight, mean (SD)       </td><td>   </td><td>0        </td><td>78.2 (19.7)</td><td>81.0 (18.7)</td><td>73.7 (21.0)</td><td>0.264    </td><td>Two Sample T-test                        </td></tr>\n",
       "<tr><td>Ethnicity, mean (SD)    </td><td>   </td><td>1        </td><td>1.9 (0.4)  </td><td>2.0 (0.5)  </td><td>1.8 (0.4)  </td><td>0.285    </td><td>Two Sample T-test                        </td></tr>\n",
       "<tr><td>Age, mean (SD)          </td><td>   </td><td>0        </td><td>38.2 (11.5)</td><td>36.7 (10.6)</td><td>40.6 (12.9)</td><td>0.319    </td><td>Two Sample T-test                        </td></tr>\n",
       "<tr><td>Employment Status, n (%)</td><td>3.0</td><td>3        </td><td>11 (28.2)  </td><td>6 (24.0)   </td><td>5 (35.7)   </td><td>0.512    </td><td>Chi-squared (warning: expected count &lt; 5)</td></tr>\n",
       "<tr><td>                        </td><td>2.0</td><td>         </td><td>17 (43.6)  </td><td>10 (40.0)  </td><td>7 (50.0)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>                        </td><td>1.0</td><td>         </td><td>1 (2.6)    </td><td>1 (4.0)    </td><td>           </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>                        </td><td>0.0</td><td>         </td><td>10 (25.6)  </td><td>8 (32.0)   </td><td>2 (14.3)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>Household Income, n (%) </td><td>1.0</td><td>3        </td><td>15 (38.5)  </td><td>7 (30.4)   </td><td>8 (50.0)   </td><td>0.682    </td><td>Chi-squared (warning: expected count &lt; 5)</td></tr>\n",
       "<tr><td>                        </td><td>2.0</td><td>         </td><td>10 (25.6)  </td><td>7 (30.4)   </td><td>3 (18.8)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>                        </td><td>3.0</td><td>         </td><td>7 (17.9)   </td><td>4 (17.4)   </td><td>3 (18.8)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>                        </td><td>4.0</td><td>         </td><td>6 (15.4)   </td><td>4 (17.4)   </td><td>2 (12.5)   </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>                        </td><td>5.0</td><td>         </td><td>1 (2.6)    </td><td>1 (4.3)    </td><td>           </td><td>         </td><td>                                         </td></tr>\n",
       "<tr><td>BMI, mean (SD)          </td><td>   </td><td>0        </td><td>25.9 (5.6) </td><td>26.2 (5.2) </td><td>25.5 (6.3) </td><td>0.687    </td><td>Two Sample T-test                        </td></tr>\n",
       "<tr><td>Education, mean (SD)    </td><td>   </td><td>1        </td><td>5.8 (1.6)  </td><td>5.8 (1.5)  </td><td>5.9 (1.9)  </td><td>0.836    </td><td>Two Sample T-test                        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                        </th><th>   </th><th>Missing  </th><th>Overall    </th><th>0          </th><th>1          </th><th>P-Value  </th><th>Test                                     </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>n                       </td><td>   </td><td>         </td><td>42         </td><td>26         </td><td>16         </td><td>         </td><td>                                         </td></tr>\\n<tr><td>Height, mean (SD)       </td><td>   </td><td>0        </td><td>1.7 (0.1)  </td><td>1.8 (0.1)  </td><td>1.7 (0.1)  </td><td>0.055    </td><td>Two Sample T-test                        </td></tr>\\n<tr><td>Race, mean (SD)         </td><td>   </td><td>0        </td><td>4.6 (1.2)  </td><td>4.9 (1.0)  </td><td>4.1 (1.4)  </td><td>0.064    </td><td>Two Sample T-test                        </td></tr>\\n<tr><td>Gender, n (%)           </td><td>O  </td><td>0        </td><td>1 (2.4)    </td><td>           </td><td>1 (6.2)    </td><td>0.084    </td><td>Chi-squared (warning: expected count &lt; 5)</td></tr>\\n<tr><td>                        </td><td>M  </td><td>         </td><td>24 (57.1)  </td><td>18 (69.2)  </td><td>6 (37.5)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>                        </td><td>F  </td><td>         </td><td>17 (40.5)  </td><td>8 (30.8)   </td><td>9 (56.2)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>Weight, mean (SD)       </td><td>   </td><td>0        </td><td>78.2 (19.7)</td><td>81.0 (18.7)</td><td>73.7 (21.0)</td><td>0.264    </td><td>Two Sample T-test                        </td></tr>\\n<tr><td>Ethnicity, mean (SD)    </td><td>   </td><td>1        </td><td>1.9 (0.4)  </td><td>2.0 (0.5)  </td><td>1.8 (0.4)  </td><td>0.285    </td><td>Two Sample T-test                        </td></tr>\\n<tr><td>Age, mean (SD)          </td><td>   </td><td>0        </td><td>38.2 (11.5)</td><td>36.7 (10.6)</td><td>40.6 (12.9)</td><td>0.319    </td><td>Two Sample T-test                        </td></tr>\\n<tr><td>Employment Status, n (%)</td><td>3.0</td><td>3        </td><td>11 (28.2)  </td><td>6 (24.0)   </td><td>5 (35.7)   </td><td>0.512    </td><td>Chi-squared (warning: expected count &lt; 5)</td></tr>\\n<tr><td>                        </td><td>2.0</td><td>         </td><td>17 (43.6)  </td><td>10 (40.0)  </td><td>7 (50.0)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>                        </td><td>1.0</td><td>         </td><td>1 (2.6)    </td><td>1 (4.0)    </td><td>           </td><td>         </td><td>                                         </td></tr>\\n<tr><td>                        </td><td>0.0</td><td>         </td><td>10 (25.6)  </td><td>8 (32.0)   </td><td>2 (14.3)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>Household Income, n (%) </td><td>1.0</td><td>3        </td><td>15 (38.5)  </td><td>7 (30.4)   </td><td>8 (50.0)   </td><td>0.682    </td><td>Chi-squared (warning: expected count &lt; 5)</td></tr>\\n<tr><td>                        </td><td>2.0</td><td>         </td><td>10 (25.6)  </td><td>7 (30.4)   </td><td>3 (18.8)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>                        </td><td>3.0</td><td>         </td><td>7 (17.9)   </td><td>4 (17.4)   </td><td>3 (18.8)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>                        </td><td>4.0</td><td>         </td><td>6 (15.4)   </td><td>4 (17.4)   </td><td>2 (12.5)   </td><td>         </td><td>                                         </td></tr>\\n<tr><td>                        </td><td>5.0</td><td>         </td><td>1 (2.6)    </td><td>1 (4.3)    </td><td>           </td><td>         </td><td>                                         </td></tr>\\n<tr><td>BMI, mean (SD)          </td><td>   </td><td>0        </td><td>25.9 (5.6) </td><td>26.2 (5.2) </td><td>25.5 (6.3) </td><td>0.687    </td><td>Two Sample T-test                        </td></tr>\\n<tr><td>Education, mean (SD)    </td><td>   </td><td>1        </td><td>5.8 (1.6)  </td><td>5.8 (1.5)  </td><td>5.9 (1.9)  </td><td>0.836    </td><td>Two Sample T-test                        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "# Demographics table\n",
    "#######################################################\n",
    "\n",
    "demos = ['Age', 'Gender', 'Height',\n",
    "       'Weight', 'BMI', 'Race',\n",
    "       'Ethnicity', 'Education',\n",
    "       'Employment Status', 'Household Income',]\n",
    "\n",
    "table = tableone.TableOne(data=clustered, \n",
    "                          categorical = ['Gender', \n",
    "                                         #'Race',\n",
    "                                         #'Ethnicity', \n",
    "                                         #'Education',\n",
    "                                         'Employment Status', \n",
    "                                         'Household Income',\n",
    "                                        ],\n",
    "                          groupby='cluster', \n",
    "                          pval=True,\n",
    "                          columns = demos,\n",
    "                         htest_name=True,\n",
    "                         sort='P-Value', label_suffix=True)\n",
    "\n",
    "table.tabulate(tablefmt=\"html\")\n",
    "#table.to_excel('PC2vsPC3_hc_demo.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "scorelist=['madrs_sum','qids_score','mddonset','mddc_duration', \n",
    "         'pss_score','lsc_score','ce_tleq','oc_tleq','rrs_total',\n",
    "         'shaps_score_1','shaps_score_2','bss_total','sticsa_somatic','sticsa_cognitive'\n",
    "          ]\n",
    "\n",
    "scoretable = tableone.TableOne(data=clustered, \n",
    "                          #categorical = scorelist,\n",
    "                          groupby='cluster', \n",
    "                          pval=True,\n",
    "                         columns = scorelist,\n",
    "                         htest_name=True,\n",
    "                         sort='P-Value', \n",
    "                         label_suffix=True\n",
    "                              )\n",
    "\n",
    "scoretable.tabulate(tablefmt=\"html\")\n",
    "scoretable.to_excel('PC2vsPC3_hc_score.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport tableone\\ntable = tableone.TableOne(data=clustered, \\n                          categorical = [\\'Male = 0 Gender\\', \\'Male = 0 Race\\', \\'Male = 0 Ethnicity\\', \\'Male = 0 Education\\'],\\n                          groupby=\\'cluster\\', \\n                          pval=True,\\n                          columns = neuropsych+[\\'cluster\\',\"MDD = 0 Age\"],\\n                         htest_name=True,\\n                         sort=\\'P-Value\\', label_suffix=True)\\n\\ntable.tabulate(tablefmt=\"html\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "# Neuropsychiatric\n",
    "#######################################################\n",
    "'''\n",
    "import tableone\n",
    "table = tableone.TableOne(data=clustered, \n",
    "                          categorical = ['Male = 0 Gender', 'Male = 0 Race', 'Male = 0 Ethnicity', 'Male = 0 Education'],\n",
    "                          groupby='cluster', \n",
    "                          pval=True,\n",
    "                          columns = neuropsych+['cluster',\"MDD = 0 Age\"],\n",
    "                         htest_name=True,\n",
    "                         sort='P-Value', label_suffix=True)\n",
    "\n",
    "table.tabulate(tablefmt=\"html\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxing/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nscores = pd.DataFrame(for_df).set_index(\\'clusters\\')\\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, dpi=200) \\nfig.set_size_inches(8, 12)\\nfig.suptitle(\"The silhouette plot for the various clusters.\")\\nfig.subplots_adjust(top=0.92)\\n\\nax1.set_ylabel(\"Silhouette Coefficient\")\\nax1.plot(scores.index,scores[\\'_silhouette_score\\'], \\'o\\',color=\\'b\\')\\nax2.plot(scores.index,scores[\\'_calinski_harabaz_score\\'],\\'x\\',color=\\'m\\' )\\nax3.plot(scores.index,scores[\\'_davies_bouldin_score\\'],\\'--\\', color=\\'c\\' )\\nax2.set_ylabel(\"Calinski-Harabaz Score\")\\nax3.set_ylabel(\"Davies Bouldin Score\")\\nax3.set_xlabel(\"Cluster label\")\\nfig.savefig(\\'sill_plot.png\\')\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "# Score graph\n",
    "#######################################################\n",
    "'''\n",
    "scores = pd.DataFrame(for_df).set_index('clusters')\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, dpi=200) \n",
    "fig.set_size_inches(8, 12)\n",
    "fig.suptitle(\"The silhouette plot for the various clusters.\")\n",
    "fig.subplots_adjust(top=0.92)\n",
    "\n",
    "ax1.set_ylabel(\"Silhouette Coefficient\")\n",
    "ax1.plot(scores.index,scores['_silhouette_score'], 'o',color='b')\n",
    "ax2.plot(scores.index,scores['_calinski_harabaz_score'],'x',color='m' )\n",
    "ax3.plot(scores.index,scores['_davies_bouldin_score'],'--', color='c' )\n",
    "ax2.set_ylabel(\"Calinski-Harabaz Score\")\n",
    "ax3.set_ylabel(\"Davies Bouldin Score\")\n",
    "ax3.set_xlabel(\"Cluster label\")\n",
    "fig.savefig('sill_plot.png')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
